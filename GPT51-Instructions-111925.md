sign by keeping all original features and create a wow new UI and update Anthropic model IDs. import os

import io

import time

import base64

import tempfile

from typing import List, Dict, Any, Tuple

from datetime import datetime

import streamlit as st

import yaml

import plotly.express as px

import plotly.graph_objects as go

from PIL import Image

import pandas as pd

# Embedded modules (combined)

import pdfplumber

from pdf2image import convert_from_bytes

import pytesseract

from openai import OpenAI

import google.generativeai as genai

from xai_sdk import Client as XAIClient

from xai_sdk.chat import user as xai_user, system as xai_system

from anthropic import Anthropic

# ==================== THEME SYSTEM ====================

FLOWER_THEMES = {

    "æ«»èŠ± Cherry Blossom": {

        "primary": "#FFB7C5",

        "secondary": "#FFC0CB",

        "accent": "#FF69B4",

        "bg_light": "linear-gradient(135deg, #ffe6f0 0%, #fff5f8 50%, #ffe6f0 100%)",

        "bg_dark": "linear-gradient(135deg, #2d1b2e 0%, #3d2533 50%, #2d1b2e 100%)",

        "icon": "ğŸŒ¸"

    },

    "ç«ç‘° Rose": {

        "primary": "#E91E63",

        "secondary": "#F06292",

        "accent": "#C2185B",

        "bg_light": "linear-gradient(135deg, #fce4ec 0%, #fff 50%, #fce4ec 100%)",

        "bg_dark": "linear-gradient(135deg, #1a0e13 0%, #2d1420 50%, #1a0e13 100%)",

        "icon": "ğŸŒ¹"

    },

    "è–°è¡£è‰ Lavender": {

        "primary": "#9C27B0",

        "secondary": "#BA68C8",

        "accent": "#7B1FA2",

        "bg_light": "linear-gradient(135deg, #f3e5f5 0%, #fff 50%, #f3e5f5 100%)",

        "bg_dark": "linear-gradient(135deg, #1a0d1f 0%, #2d1a33 50%, #1a0d1f 100%)",

        "icon": "ğŸ’œ"

    },

    "é¬±é‡‘é¦™ Tulip": {

        "primary": "#FF5722",

        "secondary": "#FF8A65",

        "accent": "#E64A19",

        "bg_light": "linear-gradient(135deg, #fbe9e7 0%, #fff 50%, #fbe9e7 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0e0a 0%, #331814 50%, #1f0e0a 100%)",

        "icon": "ğŸŒ·"

    },

    "å‘æ—¥è‘µ Sunflower": {

        "primary": "#FFC107",

        "secondary": "#FFD54F",

        "accent": "#FFA000",

        "bg_light": "linear-gradient(135deg, #fff9e6 0%, #fffef5 50%, #fff9e6 100%)",

        "bg_dark": "linear-gradient(135deg, #1f1a0a 0%, #332814 50%, #1f1a0a 100%)",

        "icon": "ğŸŒ»"

    },

    "è“®èŠ± Lotus": {

        "primary": "#E91E8C",

        "secondary": "#F48FB1",

        "accent": "#AD1457",

        "bg_light": "linear-gradient(135deg, #fce4f0 0%, #fff 50%, #fce4f0 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0e1a 0%, #331826 50%, #1f0e1a 100%)",

        "icon": "ğŸª·"

    },

    "è˜­èŠ± Orchid": {

        "primary": "#9C27B0",

        "secondary": "#CE93D8",

        "accent": "#6A1B9A",

        "bg_light": "linear-gradient(135deg, #f3e5f5 0%, #faf5ff 50%, #f3e5f5 100%)",

        "bg_dark": "linear-gradient(135deg, #1a0d1f 0%, #2d1a33 50%, #1a0d1f 100%)",

        "icon": "ğŸŒº"

    },

    "èŒ‰è‰ Jasmine": {

        "primary": "#4CAF50",

        "secondary": "#81C784",

        "accent": "#388E3C",

        "bg_light": "linear-gradient(135deg, #e8f5e9 0%, #f1f8f1 50%, #e8f5e9 100%)",

        "bg_dark": "linear-gradient(135deg, #0a1f0d 0%, #14331a 50%, #0a1f0d 100%)",

        "icon": "ğŸ¤"

    },

    "ç‰¡ä¸¹ Peony": {

        "primary": "#E91E63",

        "secondary": "#F06292",

        "accent": "#C2185B",

        "bg_light": "linear-gradient(135deg, #fce4ec 0%, #fff 50%, #fce4ec 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0e13 0%, #331826 50%, #1f0e13 100%)",

        "icon": "ğŸŒº"

    },

    "ç™¾åˆ Lily": {

        "primary": "#FFFFFF",

        "secondary": "#F5F5F5",

        "accent": "#E0E0E0",

        "bg_light": "linear-gradient(135deg, #fafafa 0%, #fff 50%, #fafafa 100%)",

        "bg_dark": "linear-gradient(135deg, #0d0d0d 0%, #1a1a1a 50%, #0d0d0d 100%)",

        "icon": "âšª"

    },

    "ç´«ç¾…è˜­ Violet": {

        "primary": "#673AB7",

        "secondary": "#9575CD",

        "accent": "#512DA8",

        "bg_light": "linear-gradient(135deg, #ede7f6 0%, #f8f5ff 50%, #ede7f6 100%)",

        "bg_dark": "linear-gradient(135deg, #0d0a1f 0%, #1a1433 50%, #0d0a1f 100%)",

        "icon": "ğŸ’œ"

    },

    "æ¢…èŠ± Plum Blossom": {

        "primary": "#E91E63",

        "secondary": "#F48FB1",

        "accent": "#C2185B",

        "bg_light": "linear-gradient(135deg, #fce4ec 0%, #fff5f8 50%, #fce4ec 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0e13 0%, #2d1a20 50%, #1f0e13 100%)",

        "icon": "ğŸŒ¸"

    },

    "èŒ¶èŠ± Camellia": {

        "primary": "#D32F2F",

        "secondary": "#EF5350",

        "accent": "#B71C1C",

        "bg_light": "linear-gradient(135deg, #ffebee 0%, #fff 50%, #ffebee 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0a0a 0%, #330d0d 50%, #1f0a0a 100%)",

        "icon": "ğŸŒ¹"

    },

    "åº·ä¹ƒé¦¨ Carnation": {

        "primary": "#F06292",

        "secondary": "#F8BBD0",

        "accent": "#E91E63",

        "bg_light": "linear-gradient(135deg, #fce4ec 0%, #fff5f8 50%, #fce4ec 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0e13 0%, #2d1a20 50%, #1f0e13 100%)",

        "icon": "ğŸ’"

    },

    "æµ·æ£  Begonia": {

        "primary": "#FF5252",

        "secondary": "#FF8A80",

        "accent": "#D50000",

        "bg_light": "linear-gradient(135deg, #ffebee 0%, #fff 50%, #ffebee 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0a0a 0%, #330d0d 50%, #1f0a0a 100%)",

        "icon": "ğŸŒº"

    },

    "æ¡‚èŠ± Osmanthus": {

        "primary": "#FF9800",

        "secondary": "#FFB74D",

        "accent": "#F57C00",

        "bg_light": "linear-gradient(135deg, #fff3e0 0%, #fffaf5 50%, #fff3e0 100%)",

        "bg_dark": "linear-gradient(135deg, #1f140a 0%, #332014 50%, #1f140a 100%)",

        "icon": "ğŸŸ¡"

    },

    "ç´«è—¤ Wisteria": {

        "primary": "#9C27B0",

        "secondary": "#BA68C8",

        "accent": "#7B1FA2",

        "bg_light": "linear-gradient(135deg, #f3e5f5 0%, #faf5ff 50%, #f3e5f5 100%)",

        "bg_dark": "linear-gradient(135deg, #1a0d1f 0%, #2d1a33 50%, #1a0d1f 100%)",

        "icon": "ğŸ’œ"

    },

    "æ°´ä»™ Narcissus": {

        "primary": "#FFEB3B",

        "secondary": "#FFF59D",

        "accent": "#F9A825",

        "bg_light": "linear-gradient(135deg, #fffde7 0%, #fffff5 50%, #fffde7 100%)",

        "bg_dark": "linear-gradient(135deg, #1f1f0a 0%, #33330d 50%, #1f1f0a 100%)",

        "icon": "ğŸŒ¼"

    },

    "æœéµ‘ Azalea": {

        "primary": "#E91E63",

        "secondary": "#F06292",

        "accent": "#C2185B",

        "bg_light": "linear-gradient(135deg, #fce4ec 0%, #fff 50%, #fce4ec 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0e13 0%, #2d1a20 50%, #1f0e13 100%)",

        "icon": "ğŸŒ¸"

    },

    "èŠ™è“‰ Hibiscus": {

        "primary": "#FF5722",

        "secondary": "#FF8A65",

        "accent": "#E64A19",

        "bg_light": "linear-gradient(135deg, #fbe9e7 0%, #fff 50%, #fbe9e7 100%)",

        "bg_dark": "linear-gradient(135deg, #1f0e0a 0%, #331814 50%, #1f0e0a 100%)",

        "icon": "ğŸŒº"

    }

}

TRANSLATIONS = {

    "zh_TW": {

        "title": "ğŸŒ¸ TFDA Agentic AIä»£ç†äººè¼”åŠ©å¯©æŸ¥ç³»çµ±",

        "subtitle": "æ™ºæ…§æ–‡ä»¶åˆ†æèˆ‡è³‡æ–™æå– AI ä»£ç†äººå¹³å°",

        "theme_selector": "é¸æ“‡èŠ±å‰ä¸»é¡Œ",

        "language": "èªè¨€",

        "dark_mode": "æ·±è‰²æ¨¡å¼",

        "upload_tab": "1) ä¸Šå‚³èˆ‡OCR",

        "preview_tab": "2) é è¦½èˆ‡ç·¨è¼¯",

        "config_tab": "3) ä»£ç†è¨­å®š",

        "execute_tab": "4) åŸ·è¡Œ",

        "dashboard_tab": "5) å„€è¡¨æ¿",

        "notes_tab": "6) å¯©æŸ¥ç­†è¨˜",

        "upload_pdf": "ä¸Šå‚³ PDF æª”æ¡ˆ",

        "ocr_mode": "OCR æ¨¡å¼",

        "ocr_lang": "OCR èªè¨€",

        "page_range": "é ç¢¼ç¯„åœ",

        "start_ocr": "é–‹å§‹ OCR",

        "save_agents": "å„²å­˜ agents.yaml",

        "download_agents": "ä¸‹è¼‰ agents.yaml",

        "reset_agents": "é‡ç½®ç‚ºé è¨­",

        "providers": "API ä¾›æ‡‰å•†",

        "connected": "å·²é€£ç·š",

        "not_connected": "æœªé€£ç·š"

    },

    "en": {

        "title": "ğŸŒ¸ TFDA Agentic AI Assistance Review System",

        "subtitle": "Intelligent Document Analysis & Data Extraction AI Agent Platform",

        "theme_selector": "Select Floral Theme",

        "language": "Language",

        "dark_mode": "Dark Mode",

        "upload_tab": "1) Upload & OCR",

        "preview_tab": "2) Preview & Edit",

        "config_tab": "3) Agent Config",

        "execute_tab": "4) Execute",

        "dashboard_tab": "5) Dashboard",

        "notes_tab": "6) Review Notes",

        "upload_pdf": "Upload PDF File",

        "ocr_mode": "OCR Mode",

        "ocr_lang": "OCR Language",

        "page_range": "Page Range",

        "start_ocr": "Start OCR",

        "save_agents": "Save agents.yaml",

        "download_agents": "Download agents.yaml",

        "reset_agents": "Reset to Default",

        "providers": "API Providers",

        "connected": "Connected",

        "not_connected": "Not Connected"

    }

}

# ==================== LLM ROUTER ====================

ModelChoice = {

    "gpt-5-nano": "openai",

    "gpt-4o-mini": "openai",

    "gpt-4.1-mini": "openai",

    "gemini-2.5-flash": "gemini",

    "gemini-2.5-flash-lite": "gemini",

    "grok-4-fast-reasoning": "grok",

    "grok-3-mini": "grok",

    "claude-sonnet-4.5": "anthropic",

    "claude-sonnet-4-20250514": "anthropic",

    "claude-haiku-4.5": "anthropic",

}

class LLMRouter:

    def __init__(self):

        self._openai_client = None

        self._gemini_ready = False

        self._xai_client = None

        self._anthropic_client = None

        self._init_clients()

    def _init_clients(self):

        if os.getenv("OPENAI_API_KEY"):

            self._openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        if os.getenv("GEMINI_API_KEY"):

            genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

            self._gemini_ready = True

        if os.getenv("XAI_API_KEY"):

            self._xai_client = XAIClient(api_key=os.getenv("XAI_API_KEY"), timeout=3600)

        if os.getenv("ANTHROPIC_API_KEY"):

            self._anthropic_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

    def generate_text(self, model_name: str, messages: List[Dict], params: Dict) -> Tuple[str, Dict, str]:

        provider = ModelChoice.get(model_name, "openai")        

        try:

            if provider == "openai":

                if not self._openai_client:

                    raise Exception("OpenAI API not configured")

                return self._openai_chat(model_name, messages, params), {"total_tokens": self._estimate_tokens(messages)}, "OpenAI"

            elif provider == "gemini":

                if not self._gemini_ready:

                    raise Exception("Gemini API not configured")

                return self._gemini_chat(model_name, messages, params), {"total_tokens": self._estimate_tokens(messages)}, "Gemini"

            elif provider == "grok":

                if not self._xai_client:

                    raise Exception("Grok API not configured")

                return self._grok_chat(model_name, messages, params), {"total_tokens": self._estimate_tokens(messages)}, "Grok"

            elif provider == "anthropic":

                if not self._anthropic_client:

                    raise Exception("Anthropic API not configured")

                return self._anthropic_chat(model_name, messages, params), {"total_tokens": self._estimate_tokens(messages)}, "Anthropic"

            else:

                raise Exception(f"Unknown provider: {provider}")

        except Exception as e:

            # Return error message instead of crashing

            return f"Error: {str(e)}", {"total_tokens": 0}, provider.capitalize() if provider else "Unknown"

    def generate_vision(self, model_name: str, prompt: str, images: List) -> str:

        provider = ModelChoice.get(model_name, "openai")

        if provider == "gemini":

            return self._gemini_vision(model_name, prompt, images)

        elif provider == "openai":

            return self._openai_vision(model_name, prompt, images)

        elif provider == "anthropic":

            return self._anthropic_vision(model_name, prompt, images)

        return "Vision not supported"

    def _openai_chat(self, model: str, messages: List, params: Dict) -> str:

        resp = self._openai_client.chat.completions.create(

            model=model,

            messages=messages,

            temperature=params.get("temperature", 0.4),

            top_p=params.get("top_p", 0.95),

            max_tokens=params.get("max_tokens", 800)

        )

        return resp.choices[0].message.content

    def _gemini_chat(self, model: str, messages: List, params: Dict) -> str:

        mm = genai.GenerativeModel(model)

        sys = "\n".join([m["content"] for m in messages if m["role"] == "system"]).strip()

        usr = "\n".join([m["content"] for m in messages if m["role"] == "user"]).strip()

        final = (sys + "\n\n" + usr).strip() if sys else usr

        resp = mm.generate_content(final, generation_config=genai.types.GenerationConfig(

            temperature=params.get("temperature", 0.4),

            top_p=params.get("top_p", 0.95),

            max_output_tokens=params.get("max_tokens", 800)

        ))

        return resp.text

    def _grok_chat(self, model: str, messages: List, params: Dict) -> str:

        chat = self._xai_client.chat.create(model=model)

        for m in messages:

            if m["role"] == "system":

                chat.append(xai_system(m["content"]))

            elif m["role"] == "user":

                chat.append(xai_user(m["content"]))

        return chat.sample().content

    def _gemini_vision(self, model: str, prompt: str, images: List) -> str:

        mm = genai.GenerativeModel(model)

        parts = [prompt] + [genai.Image.from_pil(img) for img in images]

        return mm.generate_content(parts).text

    def _openai_vision(self, model: str, prompt: str, images: List) -> str:

        contents = [{"type": "text", "text": prompt}]

        for img in images:

            buf = io.BytesIO()

            img.save(buf, format="PNG")

            b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

            contents.append({"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}})

        resp = self._openai_client.chat.completions.create(

            model=model,

            messages=[{"role": "user", "content": contents}]

        )

        return resp.choices[0].message.content

    def _estimate_tokens(self, messages: List) -> int:

        return max(1, sum(len(m.get("content", "")) for m in messages) // 4)

    def _anthropic_chat(self, model: str, messages: List, params: Dict) -> str:

    # Check if client is initialized

        if not self._anthropic_client:

            raise Exception("Anthropic API not configured. Please add ANTHROPIC_API_KEY to environment variables.")

    

    # Convert messages to Anthropic format

        system_msgs = [m["content"] for m in messages if m["role"] == "system"]

        system_prompt = "\n\n".join(system_msgs) if system_msgs else ""

        

        anthropic_messages = []

        for m in messages:

            if m["role"] == "user":

                anthropic_messages.append({"role": "user", "content": m["content"]})

            elif m["role"] == "assistant":

                anthropic_messages.append({"role": "assistant", "content": m["content"]})

        

        # If no user messages, add the system content as user message

        if not anthropic_messages:

            anthropic_messages.append({"role": "user", "content": system_prompt})

            system_prompt = ""

        

        kwargs = {

            "model": model,

            "messages": anthropic_messages,

            "temperature": params.get("temperature", 0.4),

            "top_p": params.get("top_p", 0.95),

            "max_tokens": params.get("max_tokens", 800)

        }

        

        if system_prompt:

            kwargs["system"] = system_prompt

        

        response = self._anthropic_client.messages.create(**kwargs)

        return response.content[0].text



def _anthropic_vision(self, model: str, prompt: str, images: List) -> str:

    # Check if client is initialized

    if not self._anthropic_client:

        return "Anthropic API not configured. Please add ANTHROPIC_API_KEY."

    

    # Claude Haiku doesn't support vision

    if "haiku" in model.lower():

        return "Claude Haiku doesn't support vision. Please use Sonnet models for vision tasks."

    

    content = [{"type": "text", "text": prompt}]

    

    for img in images:

        buf = io.BytesIO()

        img.save(buf, format="PNG")

        b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

        content.append({

            "type": "image",

            "source": {

                "type": "base64",

                "media_type": "image/png",

                "data": b64

            }

        })

    

    try:

        response = self._anthropic_client.messages.create(

            model=model,

            messages=[{"role": "user", "content": content}],

            max_tokens=1024

        )

        return response.content[0].text

    except Exception as e:

        return f"Error in Anthropic vision processing: {str(e)}"        

# ==================== OCR FUNCTIONS ====================

def render_pdf_pages(pdf_bytes: bytes, dpi: int = 150, max_pages: int = 30) -> List[Tuple[int, Image.Image]]:

    pages = convert_from_bytes(pdf_bytes, dpi=dpi, first_page=1, last_page=None)

    return [(idx, im) for idx, im in enumerate(pages[:max_pages])]

def extract_text_python(pdf_bytes: bytes, selected_pages: List[int], ocr_language: str = "english") -> str:

    text_parts = []

    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:

        for i in selected_pages:

            if i < len(pdf.pages):

                txt = pdf.pages[i].extract_text() or ""

                if txt.strip():

                    text_parts.append(f"[PAGE {i+1} - TEXT]\n{txt.strip()}\n")

    lang = "eng" if ocr_language == "english" else "chi_tra"

    for p in selected_pages:

        ims = convert_from_bytes(pdf_bytes, dpi=220, first_page=p+1, last_page=p+1)

        if ims:

            t = pytesseract.image_to_string(ims[0], lang=lang)

            if t.strip():

                text_parts.append(f"[PAGE {p+1} - OCR]\n{t.strip()}\n")

    return "\n".join(text_parts).strip()

def extract_text_llm(page_images: List[Image.Image], model_name: str, router) -> str:

    prompt = "è«‹å°‡åœ–ç‰‡ä¸­çš„æ–‡å­—å®Œæ•´è½‰éŒ„ï¼ˆä¿æŒåŸæ–‡ã€æ®µè½èˆ‡æ¨™é»ï¼‰ã€‚è‹¥æœ‰è¡¨æ ¼ï¼Œè«‹ä»¥Markdownè¡¨æ ¼å‘ˆç¾ã€‚"

    text_blocks = []

    for idx, im in enumerate(page_images):

        out = router.generate_vision(model_name, f"{prompt}\né é¢ {idx+1}ï¼š", [im])

        text_blocks.append(f"[PAGE {idx+1} - LLM OCR]\n{out}\n")

    return "\n".join(text_blocks).strip()

# ==================== APP CONFIG ====================

st.set_page_config(

    page_title="ğŸŒ¸ TFDA Agentic AI Assistance Review System",

    page_icon="ğŸŒ¸",

    layout="wide",

    initial_sidebar_state="expanded"

)

# ==================== SESSION STATE ====================

if "theme" not in st.session_state:

    st.session_state.theme = "æ«»èŠ± Cherry Blossom"

if "dark_mode" not in st.session_state:

    st.session_state.dark_mode = False

if "language" not in st.session_state:

    st.session_state.language = "zh_TW"

if "agents_config" not in st.session_state:

    st.session_state.agents_config = []

if "ocr_text" not in st.session_state:

    st.session_state.ocr_text = ""

if "page_images" not in st.session_state:

    st.session_state.page_images = []

if "agent_outputs" not in st.session_state:

    st.session_state.agent_outputs = []

if "selected_agent_count" not in st.session_state:

    st.session_state.selected_agent_count = 5

if "run_metrics" not in st.session_state:

    st.session_state.run_metrics = []

if "review_notes" not in st.session_state:

    st.session_state.review_notes = "# å¯©æŸ¥ç­†è¨˜\n\nåœ¨é€™è£¡è¨˜éŒ„æ‚¨çš„å¯©æŸ¥ç­†è¨˜ã€‚æ”¯æ´ Markdown æ ¼å¼ã€‚\n\nä½¿ç”¨ HTML æ¨™ç±¤æ”¹è®Šæ–‡å­—é¡è‰²ï¼Œä¾‹å¦‚ï¼š<span style='color:red'>ç´…è‰²æ–‡å­—</span>\n\n## å¾ŒçºŒå•é¡Œ\n- å•é¡Œ1ï¼Ÿ\n- å•é¡Œ2ï¼Ÿ"

# ==================== DEFAULT FDA AGENTS ====================

DEFAULT_FDA_AGENTS = """agents: 

  - name: ç”³è«‹è³‡æ–™æå–å™¨ 

    description: é€²è¡Œç¹é«”ä¸­æ–‡æ‘˜è¦ 

    system_prompt: | 

      ä½ æ˜¯ä¸€ä½é†«ç™‚å™¨ææ³•è¦å°ˆå®¶ã€‚æ ¹æ“šæä¾›çš„æ–‡ä»¶ï¼Œé€²è¡Œç¹é«”ä¸­æ–‡æ‘˜è¦in markdown in traditional chinese with keywords in coral color. Please also create a table include 20 key itemsã€‚

      - è­˜åˆ¥ï¼šå» å•†åç¨±ã€åœ°å€ã€å“åã€é¡åˆ¥ã€è­‰æ›¸ç·¨è™Ÿã€æ—¥æœŸã€æ©Ÿæ§‹ 

      - æ¨™è¨»ä¸ç¢ºå®šé …ç›®ï¼Œä¿ç•™åŸæ–‡å¼•ç”¨ 

      - ä»¥çµæ§‹åŒ–æ ¼å¼è¼¸å‡ºï¼ˆè¡¨æ ¼æˆ–JSONï¼‰ 

    user_prompt: "ä½ æ˜¯ä¸€ä½é†«ç™‚å™¨ææ³•è¦å°ˆå®¶ã€‚æ ¹æ“šæä¾›çš„æ–‡ä»¶ï¼Œé€²è¡Œç¹é«”ä¸­æ–‡æ‘˜è¦in markdown in traditional chinese with keywords in coral color. Please also create a table include 20 key itemsã€‚" 

    model: claude-sonnet-4.5 

    temperature: 0 

    top_p: 0.9 

    max_tokens: 6000 

  - name: åˆç´„è³‡æ–™åˆ†æå¸« 

    description: åˆç´„è³‡æ–™åˆ†æå¸«

    system_prompt: | 

      åˆç´„è³‡æ–™åˆ†æå¸«ï¼Œè«‹ç¢ºèªåˆç´„ä¸­åŒ…å«ä»¥ä¸‹å…§å®¹ï¼Œè«‹æ‘˜è¦åˆç´„å…§å®¹ã€‚ 

      - å§”è¨—è€…åŠå—è¨—è€…ä¹‹åç¨±åŠåœ°å€ï¼š å§”è¨—è€…(ç”²æ–¹)åç¨±ã€åœ°å€ï¼Œå—è¨—è€…(ä¹™æ–¹)åç¨±ã€åœ°å€

      - è¨—è£½é€ ä¹‹åˆæ„ï¼šå§”è¨—è€…ç¾©å‹™ã€å—è¨—è€…ç¾©å‹™ã€‚ 

      - å§”è¨—è£½é€ ä¹‹é†«ç™‚å™¨æåˆ†é¡åˆ†ç´šå“é …ï¼šå“é …åç¨±ï¼š(èˆ‰ä¾‹ M.5925 è»Ÿå¼éš±å½¢çœ¼é¡)ã€ç®¡ç†ç­‰ç´šï¼š(èˆ‰ä¾‹ç¬¬äºŒç­‰ç´š) 

      - å§”è¨—è£½é€ ä¹‹è£½ç¨‹ï¼šå§”è¨—è£½ç¨‹ç¯„åœï¼š(èˆ‰ä¾‹ï¼šå…¨éƒ¨è£½ç¨‹å§”è¨—è£½é€ ã€æ»…èŒã€åŸæ–™æº–å‚™ã€æ¨¡å…·æˆå‹ã€é¡ç‰‡åŠ å·¥ã€åŒ…è£ã€å“è³ªæª¢é©—ç­‰å…¨éƒ¨è£½ç¨‹ã€‚ 

      - å§”è¨—è€…åŠå—è¨—è€…ä¹‹æ¬Šåˆ©ç¾©å‹™ï¼šå§”è¨—è€…æ¬Šåˆ©ç¾©å‹™ï¼šèˆ‰ä¾‹ï¼šæœ‰æ¬ŠæŸ¥æ ¸è£½é€ ç´€éŒ„åŠå“è³ªç®¡ç†æ–‡ä»¶ã€‚æ‡‰æä¾›å¿…è¦ä¹‹æŠ€è¡“æ–‡ä»¶(MDF/DMR)åŠç”¢å“è¦æ ¼ã€‚æ‡‰ä¾ç´„å®šæ”¯ä»˜è£½é€ è²»ç”¨ã€‚ä¹™æ–¹æ‰€æœ‰ç”Ÿç”¢è£½ç¨‹æ‡‰ç¬¦åˆé†«ç™‚å™¨æå“è³ªç®¡ç†ç³»çµ±æº–å‰‡(QMS)åŠç›¸é—œæ³•ä»¤è¦æ±‚ã€‚ 

    user_prompt: "è«‹ç¢ºèªåˆç´„ä¸­åŒ…å«ä»¥ä¸‹å…§å®¹ï¼Œè«‹æ‘˜è¦åˆç´„å…§å®¹ in markdown in traditional chinese with keywords in coral color" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: é†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜å½¢å¼å¯©æŸ¥åˆ†æå¸« 

    description: é†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜å½¢å¼å¯©æŸ¥ 

    system_prompt: | 

      ä½ æ˜¯é†«ç™‚å™¨æå¯©æŸ¥å°ˆå®¶ï¼Œè«‹ç¢ºèªç”³è«‹è³‡æ–™åŒ…å«ä»¥ä¸‹å…§å®¹ï¼šã€‚ 

      - é¡ä¼¼å“ï¼šæ˜¯å¦æª¢é™„æœ¬éƒ¨æ ¸å‡†é¡ä¼¼å“ä¹‹ç›¸é—œè³‡æ–™

      - ç”³è«‹æ›¸ï¼šåŠ è“‹é†«ç™‚å™¨æå•†åŠè² è²¬äººå°é‘‘ã€è¼‰æ˜ç”¢å“ä¸­æ–‡åŠè‹±æ–‡åç¨±ã€å‹è™Ÿã€è¦æ ¼ã€é ˆèˆ‡è£½å”®è­‰æ˜åŠæˆæ¬Šæ›¸ç›¸ç¬¦ã€è¼‰æ˜ç”³è«‹é†«ç™‚å™¨æå•†åç¨±ã€åœ°å€ã€é ˆèˆ‡é†«ç™‚å™¨æå•†è¨±å¯åŸ·ç…§ç›¸ç¬¦ã€è¼‰æ˜è£½é€ æ¥­è€…ä¹‹åç¨±ã€åœ°å€

    user_prompt: "è«‹è©•ä¼°ä»¥ä¸‹æ–‡ä»¶ä¸­çš„ä¸è‰¯åæ‡‰è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1500 

  - name: è—¥ç‰©äº¤äº’ä½œç”¨åˆ†æå™¨ 

    description: è­˜åˆ¥è—¥ç‰©-è—¥ç‰©ã€è—¥ç‰©-é£Ÿç‰©äº¤äº’ä½œç”¨ 

    system_prompt: | 

      ä½ æ˜¯è‡¨åºŠè—¥å­¸å°ˆå®¶ï¼Œå°ˆæ³¨æ–¼äº¤äº’ä½œç”¨åˆ†æã€‚ 

      - è­˜åˆ¥ï¼šè—¥ç‰©-è—¥ç‰©ã€è—¥ç‰©-é£Ÿç‰©ã€è—¥ç‰©-ç–¾ç—…äº¤äº’ä½œç”¨ 

      - è©•ä¼°è‡¨åºŠæ„ç¾©èˆ‡è™•ç½®å»ºè­° 

      - æ¨™è¨»ç¦æ­¢ä½µç”¨èˆ‡è¬¹æ…ä½µç”¨é …ç›® 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹æ–‡ä»¶çš„è—¥ç‰©äº¤äº’ä½œç”¨ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: ç¦å¿Œç—‡èˆ‡è­¦èªæå–å™¨ 

    description: æå–ç¦å¿Œç—‡ã€è­¦èªã€æ³¨æ„äº‹é … 

    system_prompt: | 

      ä½ æ˜¯è—¥å“å®‰å…¨ç®¡ç†å°ˆå®¶ã€‚ 

      - æå–ï¼šçµ•å°ç¦å¿Œã€ç›¸å°ç¦å¿Œã€ç‰¹æ®Šè­¦èª 

      - å€åˆ†ä¸åŒåš´é‡ç¨‹åº¦ 

      - æ¨™è¨»ç‰¹æ®Šæ—ç¾¤æ³¨æ„äº‹é …ï¼ˆå­•å©¦ã€å“ºä¹³ã€å…’ç«¥ã€è€å¹´ï¼‰ 

    user_prompt: "è«‹æå–ä»¥ä¸‹æ–‡ä»¶çš„ç¦å¿Œç—‡èˆ‡è­¦èªï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è—¥å‹•å­¸åƒæ•¸æå–å™¨ 

    description: æå–å¸æ”¶ã€åˆ†å¸ƒã€ä»£è¬ã€æ’æ³„ï¼ˆADMEï¼‰è³‡è¨Š 

    system_prompt: | 

      ä½ æ˜¯è‡¨åºŠè—¥ç†å­¸å°ˆå®¶ã€‚ 

      - æå–ï¼šç”Ÿé«”å¯ç”¨ç‡ã€åŠè¡°æœŸã€æ¸…é™¤ç‡ã€åˆ†å¸ƒé«”ç© 

      - è­˜åˆ¥ä»£è¬é…µç´ ï¼ˆCYP450ç­‰ï¼‰ã€æ’æ³„é€”å¾‘ 

      - ä»¥è¡¨æ ¼å‘ˆç¾è—¥å‹•å­¸åƒæ•¸ 

    user_prompt: "è«‹æå–ä»¥ä¸‹æ–‡ä»¶çš„è—¥å‹•å­¸åƒæ•¸ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è‡¨åºŠè©¦é©—è³‡æ–™åˆ†æå™¨ 

    description: åˆ†æè‡¨åºŠè©¦é©—è¨­è¨ˆã€çµæœã€çµ±è¨ˆé¡¯è‘—æ€§ 

    system_prompt: | 

      ä½ æ˜¯è‡¨åºŠè©¦é©—å°ˆå®¶ã€‚ 

      - æå–ï¼šè©¦é©—è¨­è¨ˆï¼ˆPhase I/II/III/IVï¼‰ã€å—è©¦è€…æ•¸ã€ä¸»è¦çµ‚é» 

      - åˆ†æï¼šç™‚æ•ˆæŒ‡æ¨™ã€å®‰å…¨æ€§æ•¸æ“šã€çµ±è¨ˆé¡¯è‘—æ€§ 

      - æ¨™è¨»ç ”ç©¶é™åˆ¶èˆ‡åå·®é¢¨éšª 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹è‡¨åºŠè©¦é©—è³‡æ–™ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1500 

  - name: è—¥å“è¨±å¯è­‰è³‡è¨Šæå–å™¨ 

    description: æå–è¨±å¯è­‰å­—è™Ÿã€æ ¸å‡†æ—¥æœŸã€å» å•†è³‡è¨Š 

    system_prompt: | 

      ä½ æ˜¯è—¥æ”¿æ³•è¦å°ˆå®¶ã€‚ 

      - æå–ï¼šè¨±å¯è­‰å­—è™Ÿã€æ ¸å‡†æ—¥æœŸã€æœ‰æ•ˆæœŸé™ 

      - è­˜åˆ¥ï¼šè£½é€ å•†ã€é€²å£å•†ã€åœ‹å…§ä»£ç†å•†è³‡è¨Š 

      - æ¨™è¨»è¨±å¯è®Šæ›´æ­·å² 

    user_prompt: "è«‹æå–ä»¥ä¸‹æ–‡ä»¶çš„è¨±å¯è­‰è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 800 

  - name: ä»¿å–®è®Šæ›´æ¯”å°å™¨ 

    description: æ¯”å°ä»¿å–®ç‰ˆæœ¬å·®ç•°ï¼Œè­˜åˆ¥é‡è¦è®Šæ›´ 

    system_prompt: | 

      ä½ æ˜¯æ³•è¦æ–‡ä»¶æ¯”å°å°ˆå®¶ã€‚ 

      - è­˜åˆ¥æ–°èˆŠç‰ˆæœ¬å·®ç•°ï¼ˆæ–°å¢ã€åˆªé™¤ã€ä¿®æ”¹ï¼‰ 

      - æ¨™è¨»é‡è¦å®‰å…¨æ€§è®Šæ›´ 

      - ä»¥å°ç…§è¡¨å‘ˆç¾å·®ç•° 

    user_prompt: "è«‹æ¯”å°ä»¥ä¸‹æ–‡ä»¶çš„ç‰ˆæœ¬å·®ç•°ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 1200 

  - name: ç‰¹æ®Šæ—ç¾¤ç”¨è—¥åˆ†æå™¨ 

    description: åˆ†æå­•å©¦ã€å“ºä¹³ã€å…’ç«¥ã€è€å¹´ç”¨è—¥å®‰å…¨æ€§ 

    system_prompt: | 

      ä½ æ˜¯ç‰¹æ®Šæ—ç¾¤ç”¨è—¥å°ˆå®¶ã€‚ 

      - è©•ä¼°ï¼šå­•å©¦å®‰å…¨ç­‰ç´šã€å“ºä¹³æœŸå®‰å…¨æ€§ 

      - åˆ†æï¼šå…’ç«¥ç”¨è—¥ã€è€å¹´äººåŠ‘é‡èª¿æ•´ 

      - æ¨™è¨»è‚è…åŠŸèƒ½ä¸å…¨ç”¨è—¥å»ºè­° 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹ç‰¹æ®Šæ—ç¾¤ç”¨è—¥è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: è—¥å“å„²å­˜èˆ‡å®‰å®šæ€§åˆ†æå™¨ 

    description: æå–å„²å­˜æ¢ä»¶ã€æœ‰æ•ˆæœŸé™ã€å®‰å®šæ€§è³‡æ–™ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“å“è³ªç®¡ç†å°ˆå®¶ã€‚ 

      - æå–ï¼šå„²å­˜æº«åº¦ã€æ¿•åº¦ã€å…‰ç·šè¦æ±‚ 

      - è­˜åˆ¥ï¼šæœ‰æ•ˆæœŸé™ã€é–‹å°å¾Œæ•ˆæœŸ 

      - æ¨™è¨»ç‰¹æ®Šå„²å­˜æ³¨æ„äº‹é … 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹å„²å­˜èˆ‡å®‰å®šæ€§è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 800 

  - name: éé‡èˆ‡ä¸­æ¯’è™•ç½®åˆ†æå™¨ 

    description: åˆ†æè—¥å“éé‡ç—‡ç‹€èˆ‡è™•ç½®æ–¹å¼ 

    system_prompt: | 

      ä½ æ˜¯è‡¨åºŠæ¯’ç†å­¸å°ˆå®¶ã€‚ 

      - è­˜åˆ¥ï¼šéé‡ç—‡ç‹€ã€ä¸­æ¯’æ©Ÿè½‰ã€è‡´æ­»åŠ‘é‡ 

      - æå–ï¼šè§£æ¯’åŠ‘ã€ç·Šæ€¥è™•ç½®ã€æ”¯æŒç™‚æ³• 

      - æ¨™è¨»éœ€ç›£æ¸¬çš„ç”Ÿç†æŒ‡æ¨™ 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹éé‡èˆ‡ä¸­æ¯’è™•ç½®è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è—¥å“å¤–è§€è¾¨è­˜å™¨ 

    description: æå–è—¥å“å¤–è§€ç‰¹å¾µã€è¾¨è­˜ç¢¼ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“é‘‘åˆ¥å°ˆå®¶ã€‚ 

      - æè¿°ï¼šå½¢ç‹€ã€é¡è‰²ã€å¤§å°ã€åˆ»ç—• 

      - æå–ï¼šè—¥å“è¾¨è­˜ç¢¼ã€åŒ…è£ç‰¹å¾µ 

      - å”åŠ©é˜²å½è¾¨è­˜ 

    user_prompt: "è«‹æå–ä»¥ä¸‹è—¥å“å¤–è§€è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 800 

  - name: è³¦å½¢åŠ‘åˆ†æå™¨ 

    description: è­˜åˆ¥è³¦å½¢åŠ‘æˆåˆ†èˆ‡éæ•åŸ 

    system_prompt: | 

      ä½ æ˜¯è—¥åŠ‘å­¸å°ˆå®¶ã€‚ 

      - åˆ—å‡ºæ‰€æœ‰è³¦å½¢åŠ‘æˆåˆ† 

      - æ¨™è¨»å¸¸è¦‹éæ•åŸï¼ˆä¹³ç³–ã€éº©è³ªç­‰ï¼‰ 

      - è­˜åˆ¥è‘—è‰²åŠ‘ã€é˜²è…åŠ‘ 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹è³¦å½¢åŠ‘è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 800 

  - name: ç”¨è—¥æŒ‡å°å»ºè­°ç”Ÿæˆå™¨ 

    description: ç”Ÿæˆç—…äººç”¨è—¥æŒ‡å°è¡›æ•™è³‡æ–™ 

    system_prompt: | 

      ä½ æ˜¯è—¥å¸«è¡›æ•™å°ˆå®¶ã€‚ 

      - ä»¥æ·ºé¡¯æ˜“æ‡‚èªè¨€èªªæ˜ç”¨æ³• 

      - æä¾›æœè—¥æ™‚é–“ã€é£²é£Ÿæ³¨æ„ 

      - æ¨™è¨»æ‡‰å°±é†«çš„è­¦è¨Šç—‡ç‹€ 

    user_prompt: "è«‹ç”Ÿæˆä»¥ä¸‹è—¥å“çš„ç—…äººç”¨è—¥æŒ‡å°ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.4 

    top_p: 0.9 

    max_tokens: 1000 

  - name: æ³•è¦ç¬¦åˆæ€§æª¢æŸ¥å™¨ 

    description: æª¢æŸ¥æ–‡ä»¶æ˜¯å¦ç¬¦åˆFDAæ³•è¦è¦æ±‚ 

    system_prompt: | 

      ä½ æ˜¯è—¥æ”¿æ³•è¦ç¨½æ ¸å°ˆå®¶ã€‚ 

      - æª¢æŸ¥å¿…è¦é …ç›®å®Œæ•´æ€§ 

      - è­˜åˆ¥ç¼ºæ¼æˆ–ä¸ç¬¦åˆè¦å®šè™• 

      - æä¾›æ”¹å–„å»ºè­° 

    user_prompt: "è«‹æª¢æŸ¥ä»¥ä¸‹æ–‡ä»¶çš„æ³•è¦ç¬¦åˆæ€§ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: é¢¨éšªæ•ˆç›Šè©•ä¼°å™¨ 

    description: ç¶œåˆè©•ä¼°è—¥å“é¢¨éšªèˆ‡æ•ˆç›Š 

    system_prompt: | 

      ä½ æ˜¯è—¥å“é¢¨éšªç®¡ç†å°ˆå®¶ã€‚ 

      - é‡åŒ–ï¼šç™‚æ•ˆè­‰æ“šå¼·åº¦ã€ä¸è‰¯åæ‡‰é¢¨éšª 

      - è©•ä¼°ï¼šé¢¨éšªæ•ˆç›Šæ¯”ã€é©ç”¨æ—ç¾¤ 

      - æä¾›æ±ºç­–å»ºè­° 

    user_prompt: "è«‹è©•ä¼°ä»¥ä¸‹è—¥å“çš„é¢¨éšªæ•ˆç›Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.4 

    top_p: 0.9 

    max_tokens: 1500 

  - name: å­¸åè—¥ç”Ÿé«”ç›¸ç­‰æ€§åˆ†æå™¨ 

    description: åˆ†æå­¸åè—¥èˆ‡åŸå» è—¥ç”Ÿé«”ç›¸ç­‰æ€§ 

    system_prompt: | 

      ä½ æ˜¯ç”Ÿé«”ç›¸ç­‰æ€§è©•ä¼°å°ˆå®¶ã€‚ 

      - æå–ï¼šBEè©¦é©—è¨­è¨ˆã€AUCã€Cmaxæ•¸æ“š 

      - è©•ä¼°ï¼š90%ä¿¡è³´å€é–“ã€ç¬¦åˆæ€§ 

      - æ¨™è¨»æº¶é›¢æ›²ç·šæ¯”å°çµæœ 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹ç”Ÿé«”ç›¸ç­‰æ€§è³‡æ–™ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è—¥å“ç¶“æ¿Ÿå­¸åˆ†æå™¨ 

    description: åˆ†æè—¥å“æˆæœ¬æ•ˆç›Šèˆ‡å¥ä¿çµ¦ä»˜ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“ç¶“æ¿Ÿå­¸å°ˆå®¶ã€‚ 

      - è©•ä¼°ï¼šæˆæœ¬æ•ˆç›Šæ¯”ã€QALYã€ICER 

      - åˆ†æï¼šå¥ä¿çµ¦ä»˜æ¢ä»¶ã€æ”¯ä»˜åƒ¹æ ¼ 

      - æ¯”è¼ƒåŒé¡è—¥å“ç¶“æ¿Ÿæ€§ 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹è—¥å“ç¶“æ¿Ÿå­¸è³‡æ–™ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: è—¥å“å›æ”¶èˆ‡ä¸‹æ¶åˆ†æå™¨ 

    description: åˆ†æè—¥å“å›æ”¶åŸå› èˆ‡å½±éŸ¿ç¯„åœ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“å®‰å…¨ç›£æ§å°ˆå®¶ã€‚ 

      - è­˜åˆ¥ï¼šå›æ”¶ç­‰ç´šã€åŸå› ã€æ‰¹è™Ÿ 

      - è©•ä¼°ï¼šå½±éŸ¿ç¯„åœã€æ›¿ä»£æ–¹æ¡ˆ 

      - æä¾›è™•ç½®å»ºè­° 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹è—¥å“å›æ”¶è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1000 

  - name: ä¸Šå¸‚å¾Œç›£æ¸¬è³‡æ–™åˆ†æå™¨ 

    description: åˆ†æçœŸå¯¦ä¸–ç•Œæ•¸æ“šèˆ‡ä¸Šå¸‚å¾Œå®‰å…¨æ€§ 

    system_prompt: | 

      ä½ æ˜¯è—¥ç‰©æµè¡Œç—…å­¸å°ˆå®¶ã€‚ 

      - åˆ†æï¼šä¸è‰¯äº‹ä»¶é€šå ±ã€ä¿¡è™Ÿåµæ¸¬ 

      - è©•ä¼°ï¼šé•·æœŸå®‰å…¨æ€§ã€ç½•è¦‹é¢¨éšª 

      - è­˜åˆ¥éœ€é€²ä¸€æ­¥ç ”ç©¶çš„è­°é¡Œ 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹ä¸Šå¸‚å¾Œç›£æ¸¬è³‡æ–™ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: è—¥å“å“è³ªæª¢é©—æ¨™æº–æå–å™¨ 

    description: æå–å“è³ªè¦æ ¼èˆ‡æª¢é©—æ–¹æ³• 

    system_prompt: | 

      ä½ æ˜¯è—¥å“å“ç®¡å°ˆå®¶ã€‚ 

      - æå–ï¼šå«é‡è¦æ ¼ã€ç´”åº¦æ¨™æº– 

      - è­˜åˆ¥ï¼šæª¢é©—æ–¹æ³•ã€æ¥å—æ¨™æº– 

      - æ¨™è¨»é—œéµå“è³ªå±¬æ€§ 

    user_prompt: "è«‹æå–ä»¥ä¸‹å“è³ªæª¢é©—æ¨™æº–ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è£½ç¨‹èˆ‡è£½é€ è³‡è¨Šåˆ†æå™¨ 

    description: åˆ†æè£½é€ æµç¨‹èˆ‡GMPç¬¦åˆæ€§ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“è£½é€ å°ˆå®¶ã€‚ 

      - æè¿°ï¼šè£½ç¨‹æ­¥é©Ÿã€é—œéµåƒæ•¸ 

      - è©•ä¼°ï¼šGMPç¬¦åˆæ€§ã€å“è³ªæ§åˆ¶ 

      - è­˜åˆ¥é—œéµè£½ç¨‹æ­¥é©Ÿ 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹è£½ç¨‹è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è—¥å“åˆ†é¡èˆ‡ç®¡åˆ¶ç´šåˆ¥åˆ†æå™¨ 

    description: åˆ¤å®šè—¥å“åˆ†é¡èˆ‡ç®¡åˆ¶ç­‰ç´š 

    system_prompt: | 

      ä½ æ˜¯è—¥äº‹æ³•è¦åˆ†é¡å°ˆå®¶ã€‚ 

      - åˆ¤å®šï¼šè™•æ–¹/æŒ‡ç¤º/æˆè—¥åˆ†é¡ 

      - è­˜åˆ¥ï¼šç®¡åˆ¶è—¥å“ç´šåˆ¥ï¼ˆ1-4ç´šï¼‰ 

      - èªªæ˜ç®¡åˆ¶åŸå› èˆ‡è¦å®š 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹è—¥å“åˆ†é¡è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 800 

  - name: åœ‹éš›è—¥å…¸æ¯”å°å™¨ 

    description: æ¯”å°å„åœ‹è—¥å…¸æ¨™æº–å·®ç•° 

    system_prompt: | 

      ä½ æ˜¯åœ‹éš›è—¥å…¸å°ˆå®¶ã€‚ 

      - æ¯”å°ï¼šUSPã€BPã€EPã€JPæ¨™æº–å·®ç•° 

      - è­˜åˆ¥ï¼šå„åœ‹ç‰¹æ®Šè¦æ±‚ 

      - æä¾›ç¬¦åˆæ€§å»ºè­° 

    user_prompt: "è«‹æ¯”å°ä»¥ä¸‹åœ‹éš›è—¥å…¸æ¨™æº–ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: è—¥å“æ¨™ç±¤èˆ‡èªªæ˜æ›¸æª¢æŸ¥å™¨ 

    description: æª¢æŸ¥æ¨™ç±¤èªªæ˜æ›¸æ ¼å¼èˆ‡å®Œæ•´æ€§ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“æ¨™ç¤ºå¯©æŸ¥å°ˆå®¶ã€‚ 

      - æª¢æŸ¥ï¼šå¿…è¦è³‡è¨Šå®Œæ•´æ€§ã€æ ¼å¼è¦ç¯„ 

      - è­˜åˆ¥ï¼šå­—é«”å¤§å°ã€è­¦èªæ¨™ç¤º 

      - æä¾›ä¿®æ”¹å»ºè­° 

    user_prompt: "è«‹æª¢æŸ¥ä»¥ä¸‹æ¨™ç±¤èªªæ˜æ›¸ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.2 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è—¥å“å°ˆåˆ©åˆ†æå™¨ 

    description: åˆ†æè—¥å“å°ˆåˆ©ç‹€æ…‹èˆ‡åˆ°æœŸæ™‚é–“ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“å°ˆåˆ©åˆ†æå°ˆå®¶ã€‚ 

      - è­˜åˆ¥ï¼šæˆåˆ†å°ˆåˆ©ã€è£½ç¨‹å°ˆåˆ©ã€ç”¨é€”å°ˆåˆ© 

      - åˆ†æï¼šå°ˆåˆ©åˆ°æœŸæ™‚é–“ã€å»¶é•·ç‹€æ³ 

      - è©•ä¼°å­¸åè—¥ä¸Šå¸‚æ™‚æ©Ÿ 

    user_prompt: "è«‹åˆ†æä»¥ä¸‹è—¥å“å°ˆåˆ©è³‡è¨Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1000 

  - name: è—¥å“å‘½åè¦ç¯„æª¢æŸ¥å™¨ 

    description: æª¢æŸ¥è—¥å“å‘½åæ˜¯å¦ç¬¦åˆè¦ç¯„ 

    system_prompt: | 

      ä½ æ˜¯è—¥å“å‘½åå¯©æŸ¥å°ˆå®¶ã€‚ 

      - æª¢æŸ¥ï¼šèˆ‡æ—¢æœ‰è—¥å“ç›¸ä¼¼åº¦ 

      - è©•ä¼°ï¼šæ··æ·†é¢¨éšªã€èª¤ç”¨å¯èƒ½ 

      - æä¾›å‘½åå»ºè­° 

    user_prompt: "è«‹æª¢æŸ¥ä»¥ä¸‹è—¥å“å‘½åï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 800 

  - name: è‡¨åºŠæŒ‡å¼•æ¯”å°å™¨ 

    description: æ¯”å°è—¥å“ä½¿ç”¨èˆ‡è‡¨åºŠæŒ‡å¼•ç¬¦åˆæ€§ 

    system_prompt: | 

      ä½ æ˜¯å¯¦è­‰é†«å­¸å°ˆå®¶ã€‚ 

      - æ¯”å°ï¼šé©æ‡‰ç—‡èˆ‡æŒ‡å¼•å»ºè­° 

      - è©•ä¼°ï¼šè­‰æ“šç­‰ç´šã€å»ºè­°å¼·åº¦ 

      - è­˜åˆ¥è¶…é©æ‡‰ç—‡ä½¿ç”¨ 

    user_prompt: "è«‹æ¯”å°ä»¥ä¸‹è‡¨åºŠæŒ‡å¼•ï¼š" 

    model: gpt-4o-mini 

    temperature: 0.3 

    top_p: 0.9 

    max_tokens: 1200 

  - name: ç¶œåˆå ±å‘Šç”Ÿæˆå™¨ 

    description: æ•´åˆæ‰€æœ‰åˆ†æçµæœç”Ÿæˆå®Œæ•´å ±å‘Š 

    system_prompt: | 

      ä½ æ˜¯FDAæ–‡ä»¶æ•´åˆå°ˆå®¶ã€‚ 

      - å½™æ•´ï¼šå‰è¿°æ‰€æœ‰ä»£ç†çš„åˆ†æçµæœ 

      - ç”Ÿæˆï¼šçµæ§‹åŒ–å®Œæ•´å ±å‘Š 

      - æ¨™è¨»ï¼šé‡é»ç™¼ç¾ã€é¢¨éšªè­¦ç¤ºã€å»ºè­°äº‹é … 

      - ä»¥å°ˆæ¥­æ ¼å¼è¼¸å‡ºï¼ˆå«ç›®éŒ„ã€ç« ç¯€ï¼‰ 

    user_prompt: "è«‹æ•´åˆä»¥ä¸‹æ‰€æœ‰åˆ†æçµæœç”Ÿæˆç¶œåˆå ±å‘Šï¼š" 

    model: gpt-4o-mini 

    temperature: 0.4 

    top_p: 0.95 

    max_tokens: 2000"""

# ==================== LOAD/SAVE AGENTS ====================

def load_agents_yaml(yaml_text: str):

    try:

        data = yaml.safe_load(yaml_text)

        st.session_state.agents_config = data.get("agents", [])

        st.session_state.selected_agent_count = min(5, len(st.session_state.agents_config))

        st.session_state.agent_outputs = [

            {"input": "", "output": "", "time": 0.0, "tokens": 0, "provider": "", "model": ""}

            for _ in st.session_state.agents_config

        ]

        return True

    except Exception as e:

        st.error(f"YAML è¼‰å…¥å¤±æ•—: {e}")

        return False

# ==================== THEME GENERATOR ====================

def generate_theme_css(theme_name: str, dark_mode: bool):

    theme = FLOWER_THEMES[theme_name]

    bg = theme["bg_dark"] if dark_mode else theme["bg_light"]

    text_color = "#FFFFFF" if dark_mode else "#1a1a1a"

    card_bg = "rgba(30, 30, 30, 0.85)" if dark_mode else "rgba(255, 255, 255, 0.85)"

    border_color = theme["accent"] if dark_mode else theme["primary"]

    return f""" 

    <style> 

        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@300;400;500;700&display=swap'); 

        [data-testid="stAppViewContainer"] > .main {{ 

            background: {bg}; 

            font-family: 'Noto Sans TC', sans-serif; 

            color: {text_color}; 

        }} 

        .block-container {{ 

            padding-top: 2rem; 

            padding-bottom: 3rem; 

            max-width: 1400px; 

        }} 

        .wow-card {{ 

            background: {card_bg}; 

            backdrop-filter: blur(15px); 

            border: 2px solid {border_color}40; 

            border-radius: 20px; 

            padding: 1.5rem; 

            margin: 1rem 0; 

            box-shadow: 0 8px 32px rgba(0,0,0,0.1); 

            transition: all 0.3s ease; 

        }} 

        .wow-card:hover {{ 

            transform: translateY(-2px); 

            box-shadow: 0 12px 48px rgba(0,0,0,0.15); 

            border-color: {border_color}80; 

        }} 

        .pill {{ 

            display: inline-flex; 

            align-items: center; 

            gap: 8px; 

            background: {theme['primary']}20; 

            color: {theme['accent']}; 

            border: 2px solid {theme['primary']}40; 

            padding: 8px 16px; 

            border-radius: 999px; 

            font-weight: 600; 

            font-size: 0.95rem; 

            transition: all 0.3s ease; 

        }} 

        .pill:hover {{ 

            background: {theme['primary']}40; 

            transform: scale(1.05); 

        }} 

        .badge-ok {{ 

            background: rgba(0, 200, 83, 0.15); 

            border-color: #00C85380; 

            color: #00C853; 

        }} 

        .badge-warn {{ 

            background: rgba(255, 193, 7, 0.15); 

            border-color: #FFC10780; 

            color: #F9A825; 

        }} 

        .badge-err {{ 

            background: rgba(244, 67, 54, 0.15); 

            border-color: #F4433680; 

            color: #D32F2F; 

        }} 

        .agent-step {{ 

            border-left: 6px solid {theme['accent']}; 

            background: {card_bg}; 

            border-radius: 16px; 

            padding: 1.5rem; 

            margin: 1rem 0; 

            box-shadow: 0 4px 16px rgba(0,0,0,0.08); 

        }} 

        h1, h2, h3 {{ 

            color: {theme['accent']} !important; 

            font-weight: 700; 

        }} 

        .stButton > button {{ 

            background: linear-gradient(135deg, {theme['primary']}, {theme['secondary']}); 

            color: white; 

            border: none; 

            border-radius: 12px; 

            padding: 0.75rem 2rem; 

            font-weight: 600; 

            transition: all 0.3s ease; 

            box-shadow: 0 4px 16px {theme['primary']}40; 

        }} 

        .stButton > button:hover {{ 

            transform: translateY(-2px); 

            box-shadow: 0 8px 24px {theme['primary']}60; 

        }} 

        .stTextInput > div > div > input, .stTextArea > div > div > textarea, .stSelectbox > div > div {{ 

            background: {card_bg}; 

            border: 2px solid {border_color}40; 

            border-radius: 12px; 

            color: {text_color}; 

        }} 

        .stTabs [data-baseweb="tab-list"] {{ 

            gap: 8px; 

            background: {card_bg}; 

            border-radius: 16px; 

            padding: 0.5rem; 

        }} 

        .stTabs [data-baseweb="tab"] {{ 

            border-radius: 12px; 

            color: {text_color}; 

            font-weight: 500; 

        }} 

        .stTabs [aria-selected="true"] {{ 

            background: linear-gradient(135deg, {theme['primary']}, {theme['secondary']}); 

            color: white; 

        }} 

        .metric-card {{ 

            background: {card_bg}; 

            border: 2px solid {theme['primary']}40; 

            border-radius: 16px; 

            padding: 1.5rem; 

            text-align: center; 

            transition: all 0.3s ease; 

        }} 

        .metric-card:hover {{ 

            transform: scale(1.05); 

            border-color: {theme['accent']}; 

        }} 

        .metric-value {{ 

            font-size: 2.5rem; 

            font-weight: 700; 

            color: {theme['accent']}; 

            margin: 0.5rem 0; 

        }} 

        .metric-label {{ 

            font-size: 0.9rem; 

            color: {text_color}80; 

            font-weight: 500; 

        }} 

    </style> 

    """

# ==================== INITIALIZE ====================

router = LLMRouter()

# Load default agents if empty

if not st.session_state.agents_config:

    load_agents_yaml(DEFAULT_FDA_AGENTS)

# ==================== SIDEBAR ====================

with st.sidebar:

    t = TRANSLATIONS[st.session_state.language]

    st.markdown(f"### {t['theme_selector']}")

    new_theme = st.selectbox(

        "Theme",

        list(FLOWER_THEMES.keys()),

        index=list(FLOWER_THEMES.keys()).index(st.session_state.theme),

        format_func=lambda x: f"{FLOWER_THEMES[x]['icon']} {x}",

        label_visibility="collapsed"

    )

    if new_theme != st.session_state.theme:

        st.session_state.theme = new_theme

        st.rerun()

    col1, col2 = st.columns(2)

    with col1:

        new_dark = st.checkbox(t["dark_mode"], value=st.session_state.dark_mode)

        if new_dark != st.session_state.dark_mode:

            st.session_state.dark_mode = new_dark

            st.rerun()

    with col2:

        new_lang = st.selectbox(

            t["language"],

            ["zh_TW", "en"],

            index=0 if st.session_state.language == "zh_TW" else 1,

            format_func=lambda x: "ç¹é«”ä¸­æ–‡" if x == "zh_TW" else "English"

        )

        if new_lang != st.session_state.language:

            st.session_state.language = new_lang

            st.rerun()

    st.markdown("---")

    st.markdown(f"### ğŸ” {t['providers']}")

    def show_provider_status(name: str, env_var: str):

        connected = bool(os.getenv(env_var))

        status = t["connected"] if connected else t["not_connected"]

        badge = "badge-ok" if connected else "badge-warn"

        st.markdown(f'<div class="pill {badge}">{name}: {status}</div>', unsafe_allow_html=True)

        if not connected:

            key = st.text_input(f"{name} Key", type="password", key=f"key_{env_var}")

            if key:

                os.environ[env_var] = key

                st.success(f"{name} {t['connected']}")

    show_provider_status("OpenAI", "OPENAI_API_KEY")

    show_provider_status("Gemini", "GEMINI_API_KEY")

    show_provider_status("Grok", "XAI_API_KEY")

    show_provider_status("Anthropic", "ANTHROPIC_API_KEY")

    st.markdown("---")

    st.markdown("### ğŸ¤– Agents YAML")

    agents_text = st.text_area(

        "agents.yaml",

        value=yaml.dump({"agents": st.session_state.agents_config}, allow_unicode=True, sort_keys=False),

        height=400,

        label_visibility="collapsed"

    )

    col_a, col_b, col_c = st.columns(3)

    with col_a:

        if st.button(t["save_agents"], use_container_width=True):

            if load_agents_yaml(agents_text):

                st.success("âœ… Saved!")

    with col_b:

        st.download_button(

            t["download_agents"],

            data=agents_text,

            file_name=f"agents_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yaml",

            mime="text/yaml",

            use_container_width=True

        )

    with col_c:

        if st.button(t["reset_agents"], use_container_width=True):

            load_agents_yaml(DEFAULT_FDA_AGENTS)

            st.success("âœ… Reset!")

            st.rerun()

# Apply theme

st.markdown(generate_theme_css(st.session_state.theme, st.session_state.dark_mode), unsafe_allow_html=True)

# ==================== HEADER ====================

t = TRANSLATIONS[st.session_state.language]

theme_icon = FLOWER_THEMES[st.session_state.theme]["icon"]

col1, col2, col3 = st.columns([1, 3, 1])

with col1:

    st.markdown(f'<div class="pill">{theme_icon} TFDA AI</div>', unsafe_allow_html=True)

with col2:

    st.title(t["title"])

    st.caption(t["subtitle"])

with col3:

    providers_ok = sum([

        bool(os.getenv("OPENAI_API_KEY")),

        bool(os.getenv("GEMINI_API_KEY")),

        bool(os.getenv("XAI_API_KEY")),

        bool(os.getenv("ANTHROPIC_API_KEY"))

    ])

    st.markdown(f""" 

        <div class="wow-card"> 

            <div class="metric-value">{providers_ok}/4</div> 

            <div class="metric-label">Active Providers</div> 

        </div> 

        """, unsafe_allow_html=True)

st.markdown("---")

# ==================== TABS ====================

tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([

    t["upload_tab"],

    t["preview_tab"],

    t["config_tab"],

    t["execute_tab"],

    t["dashboard_tab"],

    t["notes_tab"]

])

# Tab 1: Upload & OCR

with tab1:

    st.markdown('<div class="wow-card">', unsafe_allow_html=True)

    st.subheader(f"{theme_icon} {t['upload_pdf']}")

    uploaded = st.file_uploader(t["upload_pdf"], type=["pdf"], label_visibility="collapsed")

    col1, col2, col3 = st.columns(3)

    with col1:

        ocr_mode = st.selectbox(

            t["ocr_mode"],

            ["Python OCR (pdfplumber + Tesseract)", "LLM OCR (Vision model)"]

        )

    with col2:

        ocr_lang = st.selectbox(t["ocr_lang"], ["english", "traditional-chinese"])

    with col3:

        page_range_input = st.text_input(t["page_range"], value="1-5")

    if ocr_mode.startswith("LLM"):

        llm_ocr_model = st.selectbox("LLM Model", [

            "gemini-2.5-flash",

            "gemini-2.5-flash-lite",

            "gpt-4o-mini",

            "claude-sonnet-4.5",

            "claude-haiku-4.5"

        ])

    if uploaded:

        pdf_bytes = uploaded.read()

        with st.spinner("Rendering pages..."):

            page_imgs = render_pdf_pages(pdf_bytes, dpi=140, max_pages=12)

        st.session_state.page_images = page_imgs

        st.caption(f"Preview (showing {len(page_imgs)} pages)")

        cols = st.columns(4)

        for i, (idx, im) in enumerate(page_imgs):

            cols[i % 4].image(im, caption=f"Page {idx+1}", use_column_width=True)

    if st.button(t["start_ocr"], type="primary", use_container_width=True):

        def parse_range(s: str, total: int) -> List[int]:

            pages = set()

            for part in s.replace("ï¼Œ", ",").split(","):

                if "-" in part:

                    a, b = map(int, part.split("-"))

                    pages.update(range(max(0, a-1), min(total, b)))

                else:

                    p = int(part) - 1

                    if 0 <= p < total:

                        pages.add(p)

            return sorted(list(pages))

        selected = parse_range(page_range_input, len(page_imgs))

        if selected:

            with st.spinner("Processing OCR..."):

                if ocr_mode.startswith("Python"):

                    text = extract_text_python(pdf_bytes, selected, ocr_lang)

                else:

                    text = extract_text_llm(

                        [page_imgs[i][1] for i in selected],

                        llm_ocr_model,

                        router

                    )

            st.session_state.ocr_text = text

            st.balloons()

            st.success("âœ… OCR Complete!")

    st.markdown('</div>', unsafe_allow_html=True)

# Tab 2: Preview & Edit

with tab2:

    st.markdown('<div class="wow-card">', unsafe_allow_html=True)

    st.subheader(f"{theme_icon} Document Text")

    st.session_state.ocr_text = st.text_area(

        "Edit OCR output",

        value=st.session_state.ocr_text,

        height=500,

        label_visibility="collapsed"

    )

    with st.expander("ğŸ” Keyword Highlighter"):

        keywords = st.text_input("Keywords (comma-separated)", value="è—¥å“,é©æ‡‰ç—‡,ä¸è‰¯åæ‡‰")

        if st.button("Highlight"):

            out = st.session_state.ocr_text

            for kw in keywords.split(","):

                kw = kw.strip()

                if kw:

                    out = out.replace(kw, f"**:blue[{kw}]**")

            st.markdown(out)

    st.markdown('</div>', unsafe_allow_html=True)

# Tab 3: Agent Config

with tab3:

    st.markdown('<div class="wow-card">', unsafe_allow_html=True)

    st.subheader(f"{theme_icon} Agent Configuration")

    st.session_state.selected_agent_count = st.slider(

        "Number of agents to use",

        1,

        len(st.session_state.agents_config),

        min(5, len(st.session_state.agents_config))

    )

    global_prompt = st.text_area(

        "Global System Prompt",

        height=150,

        value="""ä½ æ˜¯FDAæ–‡ä»¶åˆ†æå°ˆå®¶ï¼Œè«‹éµå¾ªï¼š1) ä¿æŒè³‡è¨Šæº–ç¢ºæ€§ï¼Œå¼•ç”¨åŸæ–‡æ™‚å¿…é ˆç²¾ç¢º2) çµæ§‹åŒ–è¼¸å‡ºï¼ˆè¡¨æ ¼ã€JSONã€æ¸…å–®ï¼‰3) æ¨™è¨»ä¸ç¢ºå®šé …ç›®ä¸¦èªªæ˜ç†ç”±4) è­˜åˆ¥æ½›åœ¨é¢¨éšªèˆ‡éœ€æ³¨æ„äº‹é …"""

    )

    st.markdown("---")

    for i in range(st.session_state.selected_agent_count):

        agent = st.session_state.agents_config[i]

        with st.expander(f"### Agent {i+1}: {agent.get('name', 'Unnamed')}", expanded=(i==0)):

            st.markdown('<div class="agent-step">', unsafe_allow_html=True)

            col1, col2 = st.columns([2, 1])

            with col1:

                agent["system_prompt"] = st.text_area(

                    "System Prompt",

                    value=agent.get("system_prompt", ""),

                    height=150,

                    key=f"sys_{i}"

                )

            with col2:

                agent["model"] = st.selectbox(

                    "Model",

                    ["gpt-4o-mini", "gpt-5-nano", "gemini-2.5-flash", "gemini-2.5-flash-lite",

                     "grok-3-mini", "claude-sonnet-4.5", "claude-sonnet-4-20250514", "claude-haiku-4.5"],

                    index=0,

                    key=f"model_{i}"

                )

                agent["temperature"] = st.slider("Temp", 0.0, 2.0, float(agent.get("temperature", 0.3)), 0.1, key=f"temp_{i}")

                agent["max_tokens"] = st.number_input("Max tokens", 64, 8192, int(agent.get("max_tokens", 1000)), 64, key=f"max_{i}")

            st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

# Tab 4: Execute

with tab4:

    st.markdown('<div class="wow-card">', unsafe_allow_html=True)

    st.subheader(f"{theme_icon} Execute Agent Pipeline")

    if not st.session_state.ocr_text.strip():

        st.warning("âš ï¸ Please complete OCR first (Tab 1)")

    else:

        # Initialize outputs if needed

        if len(st.session_state.agent_outputs) < len(st.session_state.agents_config):

            st.session_state.agent_outputs = [

                {"input": "", "output": "", "time": 0.0, "tokens": 0, "provider": "", "model": ""}

                for _ in st.session_state.agents_config

            ]

        # Reset first agent input

        if st.button("ğŸ”„ Reset Agent 1 Input to OCR Text"):

            st.session_state.agent_outputs[0]["input"] = st.session_state.ocr_text

            st.success("âœ… Reset!")

        st.markdown("---")

        # Agent pipeline

        for i in range(st.session_state.selected_agent_count):

            agent = st.session_state.agents_config[i]

            st.markdown(f'<div class="agent-step">', unsafe_allow_html=True)

            st.markdown(f"#### ğŸ¤– Agent {i+1}: {agent.get('name', '')}")

            st.caption(agent.get('description', ''))

            with st.expander("ğŸ“¥ Input (editable)", expanded=(i==0)):

                default_input = st.session_state.ocr_text if i == 0 and not st.session_state.agent_outputs[i]["input"] else st.session_state.agent_outputs[i]["input"]

                st.session_state.agent_outputs[i]["input"] = st.text_area(

                    f"Agent {i+1} Input",

                    value=default_input,

                    height=200,

                    key=f"in_{i}",

                    label_visibility="collapsed"

                )

            col_run, col_pass = st.columns([1, 2])

            with col_run:

                if st.button(f"â–¶ï¸ Execute Agent {i+1}", key=f"run_{i}", type="primary"):

                    with st.spinner(f"Agent {i+1} processing..."):

                        t0 = time.time()

                        messages = [

                            {"role": "system", "content": global_prompt},

                            {"role": "system", "content": agent.get("system_prompt", "")},

                            {"role": "user", "content": f"{agent.get('user_prompt', '')}\n\n{st.session_state.agent_outputs[i]['input']}"}

                        ]

                        params = {

                            "temperature": float(agent.get("temperature", 0.3)),

                            "top_p": float(agent.get("top_p", 0.95)),

                            "max_tokens": int(agent.get("max_tokens", 1000))

                        }

                        try:

                            output, usage, provider = router.generate_text(

                                agent.get("model", "gpt-4o-mini"),

                                messages,

                                params

                            )

                            elapsed = time.time() - t0

                            st.session_state.agent_outputs[i]["output"] = output

                            st.session_state.agent_outputs[i]["time"] = elapsed

                            st.session_state.agent_outputs[i]["tokens"] = usage.get("total_tokens", 0)

                            st.session_state.agent_outputs[i]["provider"] = provider

                            st.session_state.agent_outputs[i]["model"] = agent.get("model", "")

                            st.session_state.run_metrics.append({

                                "agent": agent.get("name", ""),

                                "latency": elapsed,

                                "tokens": usage.get("total_tokens", 0),

                                "provider": provider

                            })

                            st.success(f"âœ… Completed in {elapsed:.2f}s | {usage.get('total_tokens', 0)} tokens")

                            st.balloons()

                        except Exception as e:

                            st.error(f"âŒ Error: {str(e)}")

            with col_pass:

                if i < st.session_state.selected_agent_count - 1:

                    if st.button(f"â¡ï¸ Pass to Agent {i+2}", key=f"pass_{i}"):

                        st.session_state.agent_outputs[i+1]["input"] = st.session_state.agent_outputs[i]["output"]

                        st.success(f"âœ… Passed to Agent {i+2}")

                        st.rerun()

            # Show output

            st.markdown("##### ğŸ“¤ Output")

            output_text = st.session_state.agent_outputs[i]["output"]

            if output_text:

                # Metrics

                col_m1, col_m2, col_m3 = st.columns(3)

                with col_m1:

                    st.markdown(f'<div class="metric-card"><div class="metric-value">{st.session_state.agent_outputs[i]["time"]:.2f}s</div><div class="metric-label">Latency</div></div>', unsafe_allow_html=True)

                with col_m2:

                    st.markdown(f'<div class="metric-card"><div class="metric-value">{st.session_state.agent_outputs[i]["tokens"]}</div><div class="metric-label">Tokens</div></div>', unsafe_allow_html=True)

                with col_m3:

                    st.markdown(f'<div class="metric-card"><div class="metric-value">{st.session_state.agent_outputs[i]["provider"]}</div><div class="metric-label">Provider</div></div>', unsafe_allow_html=True)

                st.text_area(

                    f"Agent {i+1} Output",

                    value=output_text,

                    height=300,

                    key=f"out_{i}",

                    label_visibility="collapsed"

                )

            st.markdown('</div>', unsafe_allow_html=True)

            st.markdown("---")

        # Export options

        st.markdown("### ğŸ’¾ Export Results")

        col_j, col_m, col_r = st.columns(3)

        with col_j:

            if st.button("ğŸ“¥ Download JSON", use_container_width=True):

                import json

                payload = {

                    "timestamp": datetime.now().isoformat(),

                    "theme": st.session_state.theme,

                    "ocr_text": st.session_state.ocr_text,

                    "agents": st.session_state.agents_config[:st.session_state.selected_agent_count],

                    "outputs": st.session_state.agent_outputs[:st.session_state.selected_agent_count]

                }

                st.download_button(

                    "Download JSON",

                    data=json.dumps(payload, ensure_ascii=False, indent=2),

                    file_name=f"fda_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",

                    mime="application/json",

                    use_container_width=True

                )

        with col_m:

            if st.button("ğŸ“„ Download Markdown Report", use_container_width=True):

                report = f"# FDA Document Analysis Report\n\n"

                report += f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

                report += f"**Theme:** {st.session_state.theme}\n\n"

                report += f"## OCR Text\n\n{st.session_state.ocr_text}\n\n"

                report += "---\n\n"

                for i in range(st.session_state.selected_agent_count):

                    agent = st.session_state.agents_config[i]

                    report += f"## Agent {i+1}: {agent.get('name', '')}\n\n"

                    report += f"**Description:** {agent.get('description', '')}\n\n"

                    report += f"**Model:** {st.session_state.agent_outputs[i]['model']}\n\n"

                    report += f"**Provider:** {st.session_state.agent_outputs[i]['provider']}\n\n"

                    report += f"**Processing Time:** {st.session_state.agent_outputs[i]['time']:.2f}s\n\n"

                    report += f"### Output\n\n{st.session_state.agent_outputs[i]['output']}\n\n"

                    report += "---\n\n"

                st.download_button(

                    "Download Markdown",

                    data=report,

                    file_name=f"fda_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",

                    mime="text/markdown",

                    use_container_width=True

                )

        with col_r:

            restore_file = st.file_uploader("ğŸ“¤ Restore Session JSON", type=["json"], key="restore")

            if restore_file:

                import json

                data = json.loads(restore_file.read())

                st.session_state.ocr_text = data.get("ocr_text", "")

                st.session_state.agents_config = data.get("agents", [])

                st.session_state.agent_outputs = data.get("outputs", [])

                st.session_state.selected_agent_count = len(st.session_state.agents_config)

                st.success("âœ… Session restored!")

                st.rerun()

    st.markdown('</div>', unsafe_allow_html=True)

# Tab 5: Dashboard

with tab5:

    st.markdown('<div class="wow-card">', unsafe_allow_html=True)

    st.subheader(f"{theme_icon} Analytics Dashboard")

    if not st.session_state.run_metrics:

        st.info("ğŸ“Š No data yet. Execute agents in Tab 4 to see analytics.")

    else:

        df = pd.DataFrame(st.session_state.run_metrics)

        # Summary metrics

        col1, col2, col3, col4 = st.columns(4)

        with col1:

            total_time = df['latency'].sum()

            st.markdown(f'<div class="metric-card"><div class="metric-value">{total_time:.2f}s</div><div class="metric-label">Total Time</div></div>', unsafe_allow_html=True)

        with col2:

            total_tokens = df['tokens'].sum()

            st.markdown(f'<div class="metric-card"><div class="metric-value">{total_tokens:,}</div><div class="metric-label">Total Tokens</div></div>', unsafe_allow_html=True)

        with col3:

            avg_latency = df['latency'].mean()

            st.markdown(f'<div class="metric-card"><div class="metric-value">{avg_latency:.2f}s</div><div class="metric-label">Avg Latency</div></div>', unsafe_allow_html=True)

        with col4:

            agents_run = len(df)

            st.markdown(f'<div class="metric-card"><div class="metric-value">{agents_run}</div><div class="metric-label">Agents Run</div></div>', unsafe_allow_html=True)

        st.markdown("---")

        # Charts

        col_c1, col_c2 = st.columns(2)

        with col_c1:

            fig1 = px.bar(

                df,

                x="agent",

                y="latency",

                color="provider",

                title="Agent Latency (seconds)",

                color_discrete_map={

                    "OpenAI": "#10a37f",

                    "Gemini": "#4285f4",

                    "Grok": "#ff6b6b",

                    "Anthropic": "#d97757"

                }

            )

            fig1.update_layout(

                plot_bgcolor='rgba(0,0,0,0)',

                paper_bgcolor='rgba(0,0,0,0)',

                font=dict(color=FLOWER_THEMES[st.session_state.theme]["accent"])

            )

            st.plotly_chart(fig1, use_container_width=True)

        with col_c2:

            fig2 = px.bar(

                df,

                x="agent",

                y="tokens",

                color="provider",

                title="Token Usage by Agent",

                color_discrete_map={

                    "OpenAI": "#10a37f",

                    "Gemini": "#4285f4",

                    "Grok": "#ff6b6b",

                    "Anthropic": "#d97757"

                }

            )

            fig2.update_layout(

                plot_bgcolor='rgba(0,0,0,0)',

                paper_bgcolor='rgba(0,0,0,0)',

                font=dict(color=FLOWER_THEMES[st.session_state.theme]["accent"])

            )

            st.plotly_chart(fig2, use_container_width=True)

        # Provider distribution

        st.markdown("### Provider Distribution")

        provider_counts = df['provider'].value_counts()

        fig3 = px.pie(

            values=provider_counts.values,

            names=provider_counts.index,

            title="API Calls by Provider",

            color_discrete_map={

                "OpenAI": "#10a37f",

                "Gemini": "#4285f4",

                "Grok": "#ff6b6b",

                "Anthropic": "#d97757"

            }

        )

        fig3.update_layout(

            plot_bgcolor='rgba(0,0,0,0)',

            paper_bgcolor='rgba(0,0,0,0)',

            font=dict(color=FLOWER_THEMES[st.session_state.theme]["accent"])

        )

        st.plotly_chart(fig3, use_container_width=True)

        # Pipeline flow visualization

        st.markdown("### Pipeline Flow")

        try:

            import graphviz

            dot = graphviz.Digraph()

            dot.attr(bgcolor='transparent')

            dot.attr('node', shape='box', style='filled,rounded', fillcolor=FLOWER_THEMES[st.session_state.theme]["primary"]+'40', color=FLOWER_THEMES[st.session_state.theme]["accent"])

            for i, rec in enumerate(df.to_dict('records')):

                label = f"{i+1}. {rec['agent']}\\n{rec['provider']}\\n{rec['latency']:.2f}s | {rec['tokens']} tok"

                dot.node(f"a{i}", label)

                if i > 0:

                    dot.edge(f"a{i-1}", f"a{i}", color=FLOWER_THEMES[st.session_state.theme]["accent"])

            st.graphviz_chart(dot)

        except Exception as e:

            st.info(f"Graphviz visualization unavailable: {str(e)}")

        # Detailed table

        st.markdown("### Detailed Metrics")

        st.dataframe(

            df[['agent', 'provider', 'latency', 'tokens']].style.format({

                'latency': '{:.3f}s',

                'tokens': '{:,}'

            }),

            use_container_width=True

        )

    st.markdown('</div>', unsafe_allow_html=True)

# Tab 6: Review Notes

with tab6:

    st.markdown('<div class="wow-card">', unsafe_allow_html=True)

    st.subheader(f"{theme_icon} å¯©æŸ¥ç­†è¨˜")

    st.info("åœ¨é€™è£¡ç·¨è¼¯æ‚¨çš„å¯©æŸ¥ç­†è¨˜ã€‚æ”¯æ´ Markdown å’Œ HTML é¡è‰²æ¨™ç±¤ï¼Œä¾‹å¦‚ <span style='color:blue'>è—è‰²æ–‡å­—</span>ã€‚ç­†è¨˜æœƒè‡ªå‹•å„²å­˜æ–¼æœƒè©±ä¸­ã€‚")

    st.session_state.review_notes = st.text_area(

        "ç·¨è¼¯ç­†è¨˜",

        value=st.session_state.review_notes,

        height=500,

        label_visibility="collapsed"

    )

    st.markdown("### é è¦½ç­†è¨˜")

    st.markdown(st.session_state.review_notes, unsafe_allow_html=True)

    if st.button("ç”¢ç”Ÿå¾ŒçºŒå•é¡Œå»ºè­°"):

        with st.spinner("ç”¢ç”Ÿä¸­..."):

            messages = [

                {"role": "system", "content": "ä½ æ˜¯å¯©æŸ¥å°ˆå®¶ï¼Œè«‹æ ¹æ“šæä¾›çš„ç­†è¨˜ç”Ÿæˆ 3-5 å€‹å¾ŒçºŒå•é¡Œï¼Œä»¥ Markdown æ¸…å–®æ ¼å¼è¼¸å‡ºã€‚"},

                {"role": "user", "content": st.session_state.review_notes}

            ]

            params = {"temperature": 0.5, "max_tokens": 500}

            output, _, _ = router.generate_text("gpt-4o-mini", messages, params)

            st.session_state.review_notes += f"\n\n## å¾ŒçºŒå•é¡Œå»ºè­°ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰\n{output}"

        st.success("âœ… å·²æ–°å¢å¾ŒçºŒå•é¡Œè‡³ç­†è¨˜æœ«å°¾ï¼")

        st.rerun()

    st.markdown('</div>', unsafe_allow_html=True)

# ==================== FOOTER ====================

st.markdown("---")

st.markdown(f"""<div style="text-align: center; padding: 2rem; opacity: 0.7;"> 

    <p>{theme_icon} <strong>TFDA Agentic AI Assistance Review System</strong></p> 

    <p>Powered by OpenAI, Google Gemini, xAI Grok & Anthropic Claude â€¢ Built with Streamlit</p> 

    <p style="font-size: 0.8rem;">Â© 2024 â€¢ Theme: {st.session_state.theme}</p></div>""", unsafe_allow_html=True)

ä¸€ã€è®Šæ›´ç¸½çµï¼ˆå«çŠç‘šè‰²é—œéµå­—ï¼‰
ä»¥ä¸‹æ˜¯é‡å°åŸå§‹ç¨‹å¼ç¢¼æ‰€åšçš„è¨­è¨ˆèˆ‡æ¨¡å‹æ›´æ–°æ‘˜è¦ï¼Œä¸¦ç¶­æŒæ‰€æœ‰åŸæœ‰åŠŸèƒ½ï¼š

Anthropic æ¨¡å‹æ›´æ–°

å°‡èˆŠçš„ <span style="color:coral">claude-sonnet-4.5</span>ã€<span style="color:coral">claude-sonnet-4-20250514</span>ã€<span style="color:coral">claude-haiku-4.5</span> å…¨é¢æ›´æ–°ç‚ºæ­£å¼æ”¯æ´çš„ <span style="color:coral">Claude 3 ç³»åˆ—æ¨¡å‹ ID</span>ï¼š
<span style="color:coral">claude-3-5-sonnet-20240620</span>ï¼ˆå»ºè­°é è¨­ä¸»åŠ›ï¼‰
<span style="color:coral">claude-3-opus-20240229</span>
<span style="color:coral">claude-3-haiku-20240307</span>
åŒæ­¥æ›´æ–° <span style="color:coral">ModelChoice</span>ã€<span style="color:coral">LLM OCR æ¨¡å‹ä¸‹æ‹‰é¸å–®</span>ã€<span style="color:coral">Agent Config æ¨¡å‹é¸å–®</span> ä»¥åŠ <span style="color:coral">DEFAULT_FDA_AGENTS</span> è£¡çš„é è¨­æ¨¡å‹åç¨±ã€‚
Anthropic Router èˆ‡ Vision ä¿®æ­£

å°‡åŸæœ¬åœ¨é¡åˆ¥å¤–éƒ¨ã€ç„¡æ³•æ­£å¸¸è¢«å‘¼å«çš„ <span style="color:coral">_anthropic_vision</span> æ­£å¼ç§»å…¥ <span style="color:coral">LLMRouter</span> é¡åˆ¥å…§ï¼Œç¢ºä¿ <span style="color:coral">generate_vision</span> å¯ä»¥æ­£å¸¸å‘¼å«ã€‚
å° <span style="color:coral">_anthropic_chat</span> åšè¼•å¾®æ•´ç†ï¼Œç¶­æŒ Claude 3 message ä»‹é¢æ­£ç¢ºä½¿ç”¨ï¼Œä¸¦ä¿ç•™ä½ åŸæœ¬çš„ <span style="color:coral">system</span> / <span style="color:coral">messages</span> è¡Œç‚ºã€‚
Wow æ–° UIï¼ˆä¿ç•™æ‰€æœ‰åŸåŠŸèƒ½ï¼‰

å¼·åŒ–æ•´é«” <span style="color:coral">ç»ç’ƒæ“¬æ…‹ï¼ˆglassmorphismï¼‰</span> é¢¨æ ¼èˆ‡ <span style="color:coral">æ¼¸å±¤èƒŒæ™¯</span>ï¼Œå¢åŠ é™°å½±èˆ‡ hover å‹•ç•«ã€‚
ç¾åŒ–ï¼š
<span style="color:coral">Tabs</span>ï¼ˆæ›´åƒæ­¥é©Ÿå°è¦½ï¼‰
<span style="color:coral">Button</span>ï¼ˆæ¼¸å±¤ + æµ®èµ·æ•ˆæœï¼‰
<span style="color:coral">è¡¨æ ¼ / Metric å¡ç‰‡</span>ï¼ˆæ›´é†’ç›®çš„æ•¸æ“šé¡¯ç¤ºï¼‰
æ–°å¢ï¼š
é ‚éƒ¨ <span style="color:coral">æµç¨‹æç¤ºæ¢ï¼ˆProcess Ribbonï¼‰</span>ï¼Œå¿«é€Ÿèªªæ˜ 6 å€‹ Tab çš„ç”¨é€”ã€‚
æ›´ä¸€è‡´çš„ <span style="color:coral">å¡ç‰‡é‚Šæ¡† / åœ“è§’ / å­—å‹</span>ï¼Œè®“ UI æ›´å…·æ•´é«”æ„Ÿã€‚
å®Œå…¨ä¸è®Šæ›´ä»»ä½• <span style="color:coral">æ¥­å‹™é‚è¼¯</span>ï¼Œæ‰€æœ‰åŠŸèƒ½ï¼ˆOCRã€Agentsã€Executionã€Dashboardã€Notesï¼‰ä¿æŒåŸæ¨£ï¼Œåªæ˜¯æ›´å¥½çœ‹ã€‚
æ¥ä¸‹ä¾†æ˜¯å°æ‡‰çš„é—œéµç¨‹å¼ç¢¼ç‰‡æ®µï¼Œä½ å¯ä»¥ç›´æ¥è¦†è“‹åŸå§‹æª”ä¸­çš„ç›¸æ‡‰å€å¡Šã€‚

äºŒã€ç¨‹å¼ç¢¼æ›´æ–°é‡é»
2.1 æ›´æ–° Anthropic Model IDs èˆ‡ ModelChoice
è«‹ç”¨ä¸‹æ®µç¨‹å¼ç¢¼å–ä»£åŸæœ¬çš„ ModelChoice å®£å‘Šï¼š

# ==================== LLM ROUTER ====================
ModelChoice = {
    # OpenAI
    "gpt-5-nano": "openai",
    "gpt-4o-mini": "openai",
    "gpt-4.1-mini": "openai",

    # Google Gemini
    "gemini-2.5-flash": "gemini",
    "gemini-2.5-flash-lite": "gemini",

    # xAI Grok
    "grok-4-fast-reasoning": "grok",
    "grok-3-mini": "grok",

    # Anthropic Claude 3 ç³»åˆ—ï¼ˆæ›´æ–°å¾Œï¼‰
    "claude-3-5-sonnet-20240620": "anthropic",
    "claude-3-opus-20240229": "anthropic",
    "claude-3-haiku-20240307": "anthropic",
}
2.2 ä¿®æ­£èˆ‡å¼·åŒ– Anthropic Chat / Vision
1ï¼‰åœ¨ LLMRouter é¡åˆ¥å…§ä¿ç•™ä¸¦å¾®èª¿ _anthropic_chatï¼š

    def _anthropic_chat(self, model: str, messages: List, params: Dict) -> str:
        # ç¢ºèª client åˆå§‹åŒ–
        if not self._anthropic_client:
            raise Exception("Anthropic API not configured. Please add ANTHROPIC_API_KEY to environment variables.")

        # æ”¶é›† system è¨Šæ¯
        system_msgs = [m["content"] for m in messages if m["role"] == "system"]
        system_prompt = "\n\n".join(system_msgs) if system_msgs else ""

        # è½‰æ›ç‚º Anthropic æ ¼å¼
        anthropic_messages = []
        for m in messages:
            if m["role"] == "user":
                anthropic_messages.append({"role": "user", "content": m["content"]})
            elif m["role"] == "assistant":
                anthropic_messages.append({"role": "assistant", "content": m["content"]})

        # è‹¥æ²’æœ‰ user è¨Šæ¯ï¼Œå‰‡æŠŠ system_prompt ç•¶ä½œä¸€å€‹ user è¨Šæ¯
        if not anthropic_messages:
            anthropic_messages.append({"role": "user", "content": system_prompt})
            system_prompt = ""

        kwargs = {
            "model": model,
            "messages": anthropic_messages,
            "temperature": params.get("temperature", 0.4),
            "top_p": params.get("top_p", 0.95),
            "max_tokens": params.get("max_tokens", 800),
        }
        if system_prompt:
            kwargs["system"] = system_prompt

        response = self._anthropic_client.messages.create(**kwargs)
        return response.content[0].text
2ï¼‰å°‡ _anthropic_vision ç§»å…¥ LLMRouter é¡åˆ¥å…§ï¼Œä¸¦åˆªé™¤åŸæœ¬é¡åˆ¥å¤–é‚£å€‹å®šç¾©ï¼š

    def _anthropic_vision(self, model: str, prompt: str, images: List) -> str:
        # ç¢ºèª client åˆå§‹åŒ–
        if not self._anthropic_client:
            return "Anthropic API not configured. Please add ANTHROPIC_API_KEY."

        # Claude 3 Haiku ä¹Ÿæ”¯æ´å½±åƒï¼Œä½†è‹¥è¦é™åˆ¶å¯è¦–éœ€æ±‚èª¿æ•´
        # é€™è£¡åƒ…é¿å…èˆŠ Haiku 4.x åç¨±èª¤ç”¨ï¼Œå› æ­¤ä¸å†ç”¨ 'haiku' å­—ä¸²åˆ¤æ–·é˜»æ“‹

        content = [{"type": "text", "text": prompt}]
        for img in images:
            buf = io.BytesIO()
            img.save(buf, format="PNG")
            b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
            content.append({
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/png",
                    "data": b64
                }
            })

        try:
            response = self._anthropic_client.messages.create(
                model=model,
                messages=[{"role": "user", "content": content}],
                max_tokens=1024
            )
            return response.content[0].text
        except Exception as e:
            return f"Error in Anthropic vision processing: {str(e)}"
3ï¼‰ç¢ºèª generate_vision ä½¿ç”¨çš„æ˜¯é¡åˆ¥å…§æ–¹æ³•ï¼ˆä½ ç¾åœ¨çš„å¯«æ³•å·²æ­£ç¢ºï¼Œåªéœ€ç¢ºä¿å‡½å¼åœ¨é¡åˆ¥å…§ï¼‰ï¼š

    def generate_vision(self, model_name: str, prompt: str, images: List) -> str:
        provider = ModelChoice.get(model_name, "openai")
        if provider == "gemini":
            return self._gemini_vision(model_name, prompt, images)
        elif provider == "openai":
            return self._openai_vision(model_name, prompt, images)
        elif provider == "anthropic":
            return self._anthropic_vision(model_name, prompt, images)
        return "Vision not supported"
2.3 æ›´æ–°ä½¿ç”¨ Anthropic æ¨¡å‹çš„åœ°æ–¹
2.3.1 LLM OCR æ¨¡å‹ä¸‹æ‹‰é¸å–®
è«‹åœ¨ Tab1 (upload_tab) ä¸­ï¼Œå°‡ LLM æ¨¡å‹åˆ—è¡¨æ›´æ–°ç‚ºï¼š

    if ocr_mode.startswith("LLM"):
        llm_ocr_model = st.selectbox("LLM Model", [
            "gemini-2.5-flash",
            "gemini-2.5-flash-lite",
            "gpt-4o-mini",
            "claude-3-5-sonnet-20240620",
            "claude-3-haiku-20240307"
        ])
2.3.2 Agent Config è£¡çš„æ¨¡å‹é¸æ“‡
è«‹åœ¨ Tab3 ä¸­ agent["model"] = st.selectbox(...) é‚£æ®µæ”¹ç‚ºï¼š

                agent["model"] = st.selectbox(
                    "Model",
                    [
                        "gpt-4o-mini",
                        "gpt-5-nano",
                        "gemini-2.5-flash",
                        "gemini-2.5-flash-lite",
                        "grok-3-mini",
                        "grok-4-fast-reasoning",
                        "claude-3-5-sonnet-20240620",
                        "claude-3-opus-20240229",
                        "claude-3-haiku-20240307",
                    ],
                    index=0,
                    key=f"model_{i}"
                )
2.3.3 é è¨­ Agents YAML ä¸­çš„ Anthropic æ¨¡å‹
åœ¨ DEFAULT_FDA_AGENTS å­—ä¸²ä¸­ï¼Œç¬¬ä¸€å€‹ Agentï¼ˆã€Œç”³è«‹è³‡æ–™æå–å™¨ã€ï¼‰çš„ model è«‹æ”¹ç‚ºï¼š

    model: claude-3-5-sonnet-20240620
å…¶ä»–è‹¥æœ‰ä½¿ç”¨èˆŠ claude-sonnet-4.5 / haiku-4.5 çš„åœ°æ–¹ï¼ŒåŒæ¨£æ›æˆä¸Šé¢æ–° ID ä¸­æœ€é©åˆçš„ç‰ˆæœ¬ã€‚

2.4 Wow æ–° UIï¼šå‡ç´š generate_theme_css
ä»¥ä¸‹æ˜¯åŠ å¼·ç‰ˆçš„ CSSï¼Œä¿ç•™ä½ åŸä¾†æ‰€æœ‰ class åç¨±èˆ‡èªæ„ï¼Œä½†è®“è¦–è¦ºæ›´çµ±ä¸€ã€æœ‰å±¤æ¬¡ã€‚
è«‹ç”¨ä¸‹é¢æ•´æ®µè¦†è“‹åŸæœ¬ generate_theme_css å®šç¾©ï¼š

def generate_theme_css(theme_name: str, dark_mode: bool):
    theme = FLOWER_THEMES[theme_name]
    bg = theme["bg_dark"] if dark_mode else theme["bg_light"]
    text_color = "#FFFFFF" if dark_mode else "#1a1a1a"
    card_bg = "rgba(30, 30, 30, 0.88)" if dark_mode else "rgba(255, 255, 255, 0.92)"
    border_color = theme["accent"] if dark_mode else theme["primary"]

    return f"""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@300;400;500;700&display=swap');

        :root {{
            --primary: {theme['primary']};
            --secondary: {theme['secondary']};
            --accent: {theme['accent']};
            --text-color: {text_color};
        }}

        [data-testid="stAppViewContainer"] > .main {{
            background: {bg};
            font-family: 'Noto Sans TC', system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
            color: {text_color};
        }}

        .block-container {{
            padding-top: 1.5rem;
            padding-bottom: 3rem;
            max-width: 1440px;
        }}

        /* é ‚éƒ¨æµç¨‹å°è¦½ Ribbon */
        .process-ribbon {{
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            padding: 0.6rem 1.2rem;
            border-radius: 999px;
            background: rgba(0,0,0,0.06);
            backdrop-filter: blur(18px);
            border: 1px solid {border_color}33;
            margin-bottom: 1.2rem;
        }}
        .process-step {{
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 6px 12px;
            border-radius: 999px;
            background: {theme['primary']}1a;
            color: {text_color};
            font-size: 0.78rem;
            font-weight: 500;
        }}
        .process-step span.badge {{
            width: 18px;
            height: 18px;
            border-radius: 50%;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            font-size: 0.7rem;
            font-weight: 700;
            background: linear-gradient(135deg, {theme['primary']}, {theme['secondary']});
            color: #fff;
        }}

        /* æ ¸å¿ƒå¡ç‰‡ */
        .wow-card {{
            background: {card_bg};
            backdrop-filter: blur(18px) saturate(140%);
            border: 1.5px solid {border_color}40;
            border-radius: 22px;
            padding: 1.4rem 1.6rem;
            margin: 1.1rem 0;
            box-shadow: 0 14px 40px rgba(0,0,0,0.18);
            transition: all 0.26s ease;
            position: relative;
            overflow: hidden;
        }}
        .wow-card::before {{
            content: "";
            position: absolute;
            inset: 0;
            background: radial-gradient(circle at top left, {theme['primary']}30 0, transparent 55%);
            pointer-events: none;
        }}
        .wow-card:hover {{
            transform: translateY(-3px);
            box-shadow: 0 20px 55px rgba(0,0,0,0.26);
            border-color: {border_color}aa;
        }}

        /* å°è† å›Šæ¨™ç±¤ */
        .pill {{
            display: inline-flex;
            align-items: center;
            gap: 8px;
            background: {theme['primary']}20;
            color: {theme['accent']};
            border: 1.5px solid {theme['primary']}55;
            padding: 6px 14px;
            border-radius: 999px;
            font-weight: 600;
            font-size: 0.9rem;
            letter-spacing: 0.02em;
            transition: all 0.25s ease;
        }}
        .pill:hover {{
            background: {theme['primary']}40;
            transform: translateY(-1px) scale(1.03);
        }}

        .badge-ok {{
            background: rgba(0, 200, 83, 0.15);
            border-color: #00C85380;
            color: #00E676;
        }}
        .badge-warn {{
            background: rgba(255, 193, 7, 0.15);
            border-color: #FFC10780;
            color: #FFD54F;
        }}
        .badge-err {{
            background: rgba(244, 67, 54, 0.15);
            border-color: #F4433680;
            color: #FF8A80;
        }}

        /* Agent å€å¡Š */
        .agent-step {{
            border-left: 5px solid {theme['accent']};
            background: {card_bg};
            border-radius: 18px;
            padding: 1.35rem 1.4rem;
            margin: 0.9rem 0;
            box-shadow: 0 8px 24px rgba(0,0,0,0.15);
            position: relative;
        }}
        .agent-step::before {{
            content: "";
            position: absolute;
            left: 0;
            top: 18px;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: radial-gradient(circle, {theme['accent']} 0%, transparent 65%);
            transform: translateX(-60%);
        }}

        /* Heading æ¨£å¼ */
        h1, h2, h3 {{
            color: {theme['accent']} !important;
            font-weight: 700;
            letter-spacing: 0.02em;
        }}
        h4, h5, h6 {{
            color: {text_color};
        }}

        /* æŒ‰éˆ• */
        .stButton > button {{
            background: linear-gradient(135deg, {theme['primary']}, {theme['secondary']});
            color: #ffffff;
            border: none;
            border-radius: 14px;
            padding: 0.6rem 1.8rem;
            font-weight: 600;
            letter-spacing: 0.03em;
            transition: all 0.25s ease;
            box-shadow: 0 10px 25px {theme['primary']}50;
        }}
        .stButton > button:hover {{
            transform: translateY(-2px);
            box-shadow: 0 15px 35px {theme['primary']}90;
        }}
        .stButton > button:active {{
            transform: translateY(0px) scale(0.99);
            box-shadow: 0 6px 18px {theme['primary']}60;
        }}

        /* è¼¸å…¥å…ƒä»¶ */
        .stTextInput > div > div > input,
        .stTextArea > div > div > textarea,
        .stSelectbox > div > div,
        .stNumberInput > div > div > input {{
            background: {card_bg};
            border: 1.4px solid {border_color}55;
            border-radius: 12px;
            color: {text_color};
        }}
        .stTextInput > div > div > input:focus,
        .stTextArea > div > div > textarea:focus,
        .stSelectbox > div > div:focus,
        .stNumberInput > div > div > input:focus {{
            border-color: {theme['accent']};
            box-shadow: 0 0 0 1px {theme['accent']}80;
        }}

        /* Tabs */
        .stTabs [data-baseweb="tab-list"] {{
            gap: 6px;
            background: {card_bg};
            border-radius: 18px;
            padding: 0.4rem;
            box-shadow: 0 8px 22px rgba(0,0,0,0.16);
        }}
        .stTabs [data-baseweb="tab"] {{
            border-radius: 12px;
            color: {text_color}dd;
            font-weight: 500;
            padding: 0.4rem 1.1rem;
        }}
        .stTabs [aria-selected="true"] {{
            background: linear-gradient(135deg, {theme['primary']}, {theme['secondary']});
            color: #ffffff !important;
        }}

        /* Metric å¡ç‰‡ */
        .metric-card {{
            background: {card_bg};
            border: 1.5px solid {theme['primary']}55;
            border-radius: 18px;
            padding: 1.2rem 1.1rem;
            text-align: center;
            transition: all 0.25s ease;
        }}
        .metric-card:hover {{
            transform: translateY(-2px) scale(1.02);
            border-color: {theme['accent']};
            box-shadow: 0 12px 30px rgba(0,0,0,0.22);
        }}
        .metric-value {{
            font-size: 2.1rem;
            font-weight: 700;
            color: {theme['accent']};
            margin: 0.2rem 0 0.5rem 0;
        }}
        .metric-label {{
            font-size: 0.86rem;
            color: {text_color}aa;
            font-weight: 500;
        }}

        /* DataFrame è¡¨æ ¼ï¼ˆDashboardï¼‰ */
        .stDataFrame table tbody tr:hover {{
            background-color: {theme['primary']}1A !important;
        }}

        /* File uploader å¾®èª¿ */
        .stFileUploader > label {{
            font-weight: 600;
            color: {theme['accent']};
        }}
    </style>
    """
2.5 åœ¨ä¸»å…§å®¹å€åŠ å…¥æµç¨‹ Ribbonï¼ˆå¯é¸ä½†æ¨è–¦ï¼‰
åœ¨ä½ è¨­å®š Headerï¼ˆcol1, col2, col3 é‚£æ®µï¼‰ä¸‹æ–¹ã€st.markdown("---") ä¹‹å‰ï¼Œæ’å…¥ä¸‹é¢é€™æ®µï¼Œè®“ä½¿ç”¨è€…ä¸€çœ¼çœ‹åˆ° 6 æ­¥é©Ÿæµç¨‹ï¼š

st.markdown(
    """
    <div class="process-ribbon">
        <div class="process-step"><span class="badge">1</span> ä¸Šå‚³ & OCR</div>
        <div class="process-step"><span class="badge">2</span> é è¦½ & ç·¨è¼¯</div>
        <div class="process-step"><span class="badge">3</span> ä»£ç†è¨­å®š</div>
        <div class="process-step"><span class="badge">4</span> Pipeline åŸ·è¡Œ</div>
        <div class="process-step"><span class="badge">5</span> åˆ†æå„€è¡¨æ¿</div>
        <div class="process-step"><span class="badge">6</span> å¯©æŸ¥ç­†è¨˜</div>
    </div>
    """,
    unsafe_allow_html=True,
)
st.markdown("---")
é€™ä¸æœƒæ”¹å‹•ä»»ä½•é‚è¼¯ï¼Œåªæ˜¯åŠ ä¸€æ¢è¦–è¦ºåŒ–æµç¨‹å°è¦½ã€‚

ä¸‰ã€20 å€‹å¯¦é«”ï¼ˆEntitiesï¼‰è¡¨æ ¼èˆ‡ JSON
ä»¥ä¸‹ç”¨ä½ çš„ç³»çµ±ä¸»è¦æ§‹ä»¶å®šç¾© 20 å€‹å¯¦é«”ï¼Œå¯ç”¨æ–¼å¾ŒçºŒçµæ§‹åŒ–è¨­å®šæˆ–æ–‡ä»¶åŒ–ã€‚

3.1 20 å€‹å¯¦é«”è¡¨æ ¼ï¼ˆMarkdown Tableï¼‰
Entity ID	åç¨±	é¡å‹	è§’è‰² / åŠŸèƒ½èªªæ˜
E01	ThemeSystem	UI/Config	ç®¡ç†èŠ±å‰ä¸»é¡Œã€æ·±è‰²æ¨¡å¼èˆ‡å…¨å±€é…è‰²
E02	TranslationManager	i18n	æ ¹æ“š TRANSLATIONS æä¾›å¤šèªç³»æ–‡å­—ï¼ˆç¹ä¸­ / è‹±æ–‡ï¼‰
E03	LLMRouter	Core Service	æ ¹æ“šæ¨¡å‹ ID è·¯ç”±è‡³ OpenAI / Gemini / Grok / Anthropic
E04	AnthropicClient	Provider	å°è£èˆ‡ Anthropic Claude 3 ç³»åˆ—æ¨¡å‹äº’å‹•çš„ç´°ç¯€
E05	OCRPythonEngine	OCR	çµåˆ pdfplumber èˆ‡ pytesseract åŸ·è¡Œå‚³çµ± OCR
E06	OCRLlmVisionEngine	OCR	ä½¿ç”¨ Vision æ¨¡å‹é€²è¡Œ LLM OCRï¼ˆå«åœ–ç‰‡æ–‡å­—èˆ‡è¡¨æ ¼è½‰éŒ„ï¼‰
E07	PdfRenderer	Rendering	å°‡ PDF bytes è½‰ç‚ºåˆ†é  PIL.Image é è¦½
E08	AgentConfigStore	State/Config	ä»¥ agents.yaml å®šç¾©ä¸¦å„²å­˜æ‰€æœ‰ Agent è¨­å®š
E09	AgentExecutor	Orchestrator	è² è²¬é€å€‹åŸ·è¡Œ Agentã€ä¸²æ¥ input/outputã€æ”¶é›† latency/token ç­‰æŒ‡æ¨™
E10	MetricsRecorder	Analytics	å„²å­˜æ¯æ¬¡ Agent åŸ·è¡Œçš„ latency / tokens / provider ä»¥ä¾› Dashboard ä½¿ç”¨
E11	DashboardView	UI View	ä½¿ç”¨ Plotly èˆ‡ Graphviz é¡¯ç¤º Token/Latency/Provider åˆ†å¸ƒèˆ‡ Pipeline æµç¨‹
E12	ReviewNotesEditor	UI View	Markdown + HTML ç­†è¨˜ç·¨è¼¯å€ï¼Œä¸¦å¯è‡ªå‹•ç”¢ç”Ÿå¾ŒçºŒå•é¡Œå»ºè­°
E13	OcrTextBuffer	State	å„²å­˜ OCR çµæœæ–‡å­—ï¼Œä¾›ä¸‹æ¸¸ Agent æˆ–äººå·¥ç·¨ä¿®ä½¿ç”¨
E14	AgentOutputBuffer	State	å„²å­˜æ¯å€‹ Agent çš„ input/outputã€æ™‚é–“èˆ‡ Token ä½¿ç”¨æƒ…æ³
E15	ProviderStatusPanel	UI Component	å´é‚Šæ¬„é¡¯ç¤ºå„ API Provider æ˜¯å¦å·²é€£ç·šï¼Œä¸¦æ”¯æ´å‹•æ…‹è¼¸å…¥ API Key
E16	ThemeCssGenerator	UI/Style	generate_theme_cssï¼Œç”¢ç”Ÿæ•´å¥— glassmorphism + æ¼¸å±¤é¢¨æ ¼ CSS
E17	ReportExporter	Export	åŒ¯å‡º JSON èˆ‡ Markdown å ±å‘Šï¼ŒåŒ…å« Agents è¨­å®šèˆ‡åŸ·è¡Œçµæœ
E18	SessionRestorer	Import	å¾ JSON é‚„åŸæ•´å€‹ Sessionï¼ˆOCR / Agents / Outputsï¼‰
E19	KeywordHighlighter	Utility	åœ¨é è¦½æ–‡å­—ä¸­ç”¨ Markdown æ¨™è¨˜é—œéµå­—ï¼Œå”åŠ©å¿«é€Ÿé–±è®€
E20	ProcessRibbon	UI Component	é ‚éƒ¨æµç¨‹å°è¦½ Ribbonï¼Œè¦–è¦ºåŒ–å‘ˆç¾ 1â€“6 æ­¥é©Ÿå·¥ä½œæµç¨‹
3.2 20 å€‹å¯¦é«”çš„ JSON çµæ§‹
[
  {
    "id": "E01",
    "name": "ThemeSystem",
    "type": "UI/Config",
    "description": "ç®¡ç†èŠ±å‰ä¸»é¡Œã€æ·±è‰²æ¨¡å¼èˆ‡å…¨å±€é…è‰²ï¼Œå½±éŸ¿æ•´é«”è¦–è¦ºé¢¨æ ¼ã€‚",
    "status": "active"
  },
  {
    "id": "E02",
    "name": "TranslationManager",
    "type": "i18n",
    "description": "æ ¹æ“š TRANSLATIONS å­—å…¸æä¾›ç¹é«”ä¸­æ–‡èˆ‡è‹±æ–‡ UI æ–‡æ¡ˆã€‚",
    "status": "active"
  },
  {
    "id": "E03",
    "name": "LLMRouter",
    "type": "Core Service",
    "description": "æ ¹æ“šæ¨¡å‹ ID å°‡è«‹æ±‚è·¯ç”±åˆ° OpenAIã€Google Geminiã€xAI Grok æˆ– Anthropicã€‚",
    "status": "active"
  },
  {
    "id": "E04",
    "name": "AnthropicClient",
    "type": "Provider",
    "description": "å°è£èˆ‡ Anthropic Claude 3 ç³»åˆ—æ¨¡å‹çš„æ–‡å­—èˆ‡è¦–è¦ºè¨Šæ¯äº’å‹•ã€‚",
    "status": "active"
  },
  {
    "id": "E05",
    "name": "OCRPythonEngine",
    "type": "OCR",
    "description": "ä½¿ç”¨ pdfplumber è®€å–æ–‡å­—ä¸¦ç”¨ Tesseract å°å½±åƒéƒ¨åˆ†é€²è¡Œ OCRã€‚",
    "status": "active"
  },
  {
    "id": "E06",
    "name": "OCRLlmVisionEngine",
    "type": "OCR",
    "description": "é€éæ”¯æ´ Vision çš„ LLM å° PDF å½±åƒé€²è¡Œé«˜å“è³ª OCR èˆ‡è¡¨æ ¼çµæ§‹é‡å»ºã€‚",
    "status": "active"
  },
  {
    "id": "E07",
    "name": "PdfRenderer",
    "type": "Rendering",
    "description": "å°‡ä¸Šå‚³çš„ PDF bytes è½‰æ›ç‚ºåˆ†é  PIL åœ–ç‰‡ä»¥ä¾›é è¦½èˆ‡ OCR ä½¿ç”¨ã€‚",
    "status": "active"
  },
  {
    "id": "E08",
    "name": "AgentConfigStore",
    "type": "State/Config",
    "description": "é€é agents.yaml å„²å­˜èˆ‡è¼‰å…¥æ‰€æœ‰ AI Agent çš„è¨­å®šèˆ‡æç¤ºè©ã€‚",
    "status": "active"
  },
  {
    "id": "E09",
    "name": "AgentExecutor",
    "type": "Orchestrator",
    "description": "ç®¡ç† Agent pipeline åŸ·è¡Œé †åºã€è¼¸å…¥å‚³éèˆ‡éŒ¯èª¤è™•ç†ã€‚",
    "status": "active"
  },
  {
    "id": "E10",
    "name": "MetricsRecorder",
    "type": "Analytics",
    "description": "è¨˜éŒ„å„ Agent åŸ·è¡Œçš„ latencyã€token ä½¿ç”¨èˆ‡ provider è³‡è¨Šï¼Œä¾› Dashbord åˆ†æã€‚",
    "status": "active"
  },
  {
    "id": "E11",
    "name": "DashboardView",
    "type": "UI View",
    "description": "ä½¿ç”¨ Plotly èˆ‡ Graphviz é¡¯ç¤ºåˆ†æåœ–è¡¨èˆ‡ pipeline æµç¨‹åœ–ã€‚",
    "status": "active"
  },
  {
    "id": "E12",
    "name": "ReviewNotesEditor",
    "type": "UI View",
    "description": "æä¾› Markdown + HTML æ”¯æ´çš„å¯©æŸ¥ç­†è¨˜ç·¨è¼¯å™¨èˆ‡è‡ªå‹•å•é¡Œå»ºè­°åŠŸèƒ½ã€‚",
    "status": "active"
  },
  {
    "id": "E13",
    "name": "OcrTextBuffer",
    "type": "State",
    "description": "å„²å­˜ä¸¦åˆ†äº« OCR çµæœæ–‡å­—çµ¦å¾ŒçºŒ Agent æˆ–äººå·¥ç·¨è¼¯æ­¥é©Ÿã€‚",
    "status": "active"
  },
  {
    "id": "E14",
    "name": "AgentOutputBuffer",
    "type": "State",
    "description": "ä¿å­˜æ¯å€‹ Agent çš„è¼¸å…¥ã€è¼¸å‡ºã€åŸ·è¡Œæ™‚é–“èˆ‡ token çµ±è¨ˆè³‡è¨Šã€‚",
    "status": "active"
  },
  {
    "id": "E15",
    "name": "ProviderStatusPanel",
    "type": "UI Component",
    "description": "å´é‚Šæ¬„é¡¯ç¤ºä¸¦ç®¡ç†å„ API Provider çš„é€£ç·šç‹€æ…‹èˆ‡é‡‘é‘°è¼¸å…¥ã€‚",
    "status": "active"
  },
  {
    "id": "E16",
    "name": "ThemeCssGenerator",
    "type": "UI/Style",
    "description": "é€é generate_theme_css å»ºç«‹ glassmorphism èˆ‡èŠ±å‰ä¸»é¡Œé¢¨æ ¼çš„ CSSã€‚",
    "status": "active"
  },
  {
    "id": "E17",
    "name": "ReportExporter",
    "type": "Export",
    "description": "å°‡åˆ†æçµæœè¼¸å‡ºç‚º JSON æˆ– Markdown å ±å‘Šï¼Œæ–¹ä¾¿æ­¸æª”èˆ‡åˆ†äº«ã€‚",
    "status": "active"
  },
  {
    "id": "E18",
    "name": "SessionRestorer",
    "type": "Import",
    "description": "å¾å…ˆå‰åŒ¯å‡ºçš„ JSON æª”æ¡ˆé‚„åŸæ•´å€‹å·¥ä½œéšæ®µçš„ç‹€æ…‹ã€‚",
    "status": "active"
  },
  {
    "id": "E19",
    "name": "KeywordHighlighter",
    "type": "Utility",
    "description": "åœ¨ OCR æ–‡å­—ä¸­æ¨™è¨˜æŒ‡å®šé—œéµå­—ä»¥æå‡é–±è®€æ•ˆç‡ã€‚",
    "status": "active"
  },
  {
    "id": "E20",
    "name": "ProcessRibbon",
    "type": "UI Component",
    "description": "é ‚éƒ¨çš„ 6 æ­¥é©Ÿæµç¨‹å°è¦½åˆ—ï¼Œå”åŠ©ä½¿ç”¨è€…ç†è§£æ•´é«”ä½œæ¥­é †åºã€‚",
    "status": "active"
  }
]
å››ã€20 å€‹å¾ŒçºŒæ·±å…¥å•é¡Œï¼ˆä¾›ä½ æ€è€ƒä¸‹ä¸€æ­¥å„ªåŒ–æ–¹å‘ï¼‰
ä½ æ˜¯å¦éœ€è¦é‡å°ä¸åŒæ–‡ä»¶é¡å‹ï¼ˆä»¿å–®ã€åˆç´„ã€è‡¨åºŠè©¦é©—å ±å‘Šï¼‰è‡ªå‹•é¸æ“‡æœ€é©åˆçš„ <span style="color:coral">Agent çµ„åˆ</span> èˆ‡ <span style="color:coral">æ¨¡å‹</span>ï¼Ÿ
æ˜¯å¦è€ƒæ…®åŠ å…¥ <span style="color:coral">æª”æ¡ˆé¡å‹åµæ¸¬</span>ï¼ˆPDF / åœ–ç‰‡ / Wordï¼‰ï¼Œè‡ªå‹•é¸ç”¨å°æ‡‰ OCR æˆ–è§£ææµç¨‹ï¼Ÿ
ç›®å‰ä½¿ç”¨è€…éœ€æ‰‹å‹•æŒ‡å®š <span style="color:coral">é ç¢¼ç¯„åœ</span>ï¼Œæ˜¯å¦è¦åŠ å…¥é é¢ç¸®åœ–é»é¸æ©Ÿåˆ¶ï¼ˆå¤šé¸å‹¾é¸é é¢ï¼‰ä¾†æå‡æ˜“ç”¨æ€§ï¼Ÿ
ä½ æ˜¯å¦å¸Œæœ›åœ¨ Dashboard ä¸­æ–°å¢ <span style="color:coral">æˆæœ¬ä¼°ç®—</span>ï¼ˆä¾ provider / token åƒ¹æ ¼ä¼°è¨ˆç•¶æ¬¡åˆ†æçš„è²»ç”¨ï¼‰ï¼Ÿ
å°æ–¼ <span style="color:coral">agents.yaml</span>ï¼Œæ˜¯å¦è¦æä¾›åœ–å½¢åŒ–ç·¨è¼¯å™¨ï¼ˆè¡¨å–®å¼ï¼‰ï¼Œè€Œä¸åªæ–‡å­—å€å¡Šç·¨è¼¯ï¼Ÿ
æ˜¯å¦éœ€è¦ <span style="color:coral">ç‰ˆæœ¬ç®¡ç†</span> åŠŸèƒ½ï¼Œä»¥è¿½è¹¤ä¸åŒ agents.yaml èˆ‡åˆ†æå ±å‘Šçš„ç‰ˆæœ¬å·®ç•°ï¼Ÿ
ä½ æ˜¯å¦å¸Œæœ›åœ¨ Review Notes ä¸­ç›´æ¥å¼•ç”¨ <span style="color:coral">ç‰¹å®š Agent çš„è¼¸å‡ºæ®µè½</span>ï¼Œä¾‹å¦‚ç”¨è‡ªå‹•ç”¢ç”Ÿçš„è¶…é€£çµæˆ–å¼•ç”¨å€å¡Šï¼Ÿ
æ˜¯å¦è€ƒæ…®åœ¨ Execution Tab åŠ å…¥ <span style="color:coral">ä¸€éµå…¨åŸ·è¡Œ</span> èˆ‡ <span style="color:coral">è‡ªè¨‚åŸ·è¡Œé †åº</span>ï¼ˆæ‹–æ‹‰æ’åºï¼‰åŠŸèƒ½ï¼Ÿ
ç•¶æŸäº› Provider æœªé€£ç·šæ™‚ï¼Œæ˜¯å¦éœ€è¦ <span style="color:coral">è‡ªå‹• fallback</span> åˆ°å…¶å®ƒæ¨¡å‹æˆ–é¡¯ç¤ºæ›¿ä»£å»ºè­°ï¼Ÿ
ä½ æ˜¯å¦éœ€è¦é‡å° <span style="color:coral">æ•æ„Ÿé†«ç™‚è³‡æ–™</span> åŠ å…¥é¡å¤–çš„éš±ç§è™•ç†ï¼ˆå¦‚è‡ªå‹•è„«æ•æ¬„ä½ã€ç§»é™¤å€‹è³‡ï¼‰ï¼Ÿ
æ˜¯å¦è¦åœ¨ UI ä¸­å° <span style="color:coral">éŒ¯èª¤æ—¥èªŒ</span> åšå¯è¦–åŒ–ï¼Œä¾‹å¦‚é¡¯ç¤ºæœ€è¿‘ N æ¬¡å¤±æ•—åŸå› çµ±è¨ˆèˆ‡æç¤ºï¼Ÿ
ä½ æ˜¯å¦æƒ³è¦ç‚ºå¸¸ç”¨çš„ <span style="color:coral">åˆ†ææ¨¡æ¿</span>ï¼ˆä¾‹å¦‚ã€Œæ–°è—¥æŸ¥é©—ç™»è¨˜ã€ï¼‰å»ºç«‹é è¨­å·¥ä½œæµç¨‹æŒ‰éˆ•ï¼Œä¸€éµå¥—ç”¨ agents.yaml + å…¨åŸ·è¡Œï¼Ÿ
å°æ–¼ <span style="color:coral">LLM OCR</span> çš„çµæœï¼Œä½ æ˜¯å¦éœ€è¦å†åŠ ä¸Šä¸€å±¤ <span style="color:coral">çµæ§‹åŒ–å¾Œè™•ç†</span>ï¼ˆè‡ªå‹•æŠ½å‡ºè¡¨æ ¼ / æ¬„ä½ï¼‰ä¾›å¾ŒçºŒç¨‹å¼ç›´æ¥ä½¿ç”¨ï¼Ÿ
æ˜¯å¦è€ƒæ…®æ–°å¢ <span style="color:coral">å¤šæª”æ¡ˆæ‰¹æ¬¡è™•ç†</span> æ¨¡å¼ï¼Œè®“ä½¿ç”¨è€…ä¸€æ¬¡ä¸Šå‚³å¤šä»½ PDF ä¸¦ç”¢å‡ºæ•´åˆå ±å‘Šï¼Ÿ
åœ¨ Dashboard ä¸­ï¼Œä½ æ˜¯å¦éœ€è¦ <span style="color:coral">æ™‚é–“åºåˆ—</span> è¦–è§’ï¼Œåˆ†æé•·æœŸä½¿ç”¨è¶¨å‹¢ï¼ˆæ¯é€± / æ¯æœˆ tokens / æ¬¡æ•¸ï¼‰ï¼Ÿ
æ˜¯å¦è¦ç‚ºä¸åŒä½¿ç”¨è€…æˆ–åœ˜éšŠæä¾› <span style="color:coral">å€‹äººåŒ–ä¸»é¡Œèˆ‡é è¨­è¨­å®š</span>ï¼Œä¾‹å¦‚é è¨­èªè¨€ã€é è¨­æ¨¡å‹èˆ‡é è¨­ Agents æ¸…å–®ï¼Ÿ
å°æ–¼ <span style="color:coral">æ³•è¦ç¬¦åˆæ€§æª¢æŸ¥å™¨</span> ç­‰é—œéµ Agentï¼Œä½ æ˜¯å¦éœ€è¦é¡å¤–çš„ <span style="color:coral">å¯©è¨ˆç´€éŒ„</span>ï¼ˆèª°åœ¨ä½•æ™‚ç”¨å“ªå€‹ç‰ˆæœ¬é€²è¡Œäº†å“ªä»½æ–‡ä»¶çš„æª¢æŸ¥ï¼‰ï¼Ÿ
æ˜¯å¦è¦åŠ å…¥ <span style="color:coral">æ¬Šé™ç®¡ç†</span>ï¼ˆä¾‹å¦‚æŸäº›æ•æ„Ÿ Agent åªèƒ½ç”±ç‰¹å®šè§’è‰²åŸ·è¡Œï¼Œæˆ–éœ€è¦äºŒæ¬¡ç¢ºèªï¼‰ï¼Ÿ
ä½ æ˜¯å¦æœ‰éœ€è¦å°‡æœ¬ç³»çµ±è¼¸å‡ºçš„ <span style="color:coral">JSON</span> ç›´æ¥å°æ¥åˆ°å…¶ä»–å…§éƒ¨ç³»çµ±ï¼ˆå¦‚ TFDA å…§éƒ¨å·¥ä½œæµç¨‹ç³»çµ±æˆ–è³‡æ–™åº«ï¼‰ï¼Ÿ
åœ¨ã€ŒWow UIã€æ–¹é¢ï¼Œæ˜¯å¦é‚„å¸Œæœ›åŠ ä¸Š <span style="color:coral">ä½¿ç”¨è€…å°è¦½æ•™å­¸</span>ï¼ˆå¦‚é¦–æ¬¡ä½¿ç”¨æ™‚çš„ step-by-step highlight æ•™å­¸ï¼‰ä¾†é™ä½æ–°æ‰‹ä¸Šæ‰‹é–€æª»ï¼Ÿ
